{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for disabling the components of a pipeline:\n",
    "```python\n",
    "for doc in nlp.pipe(\"blah blah blah\", disable=[\"tagger\", \"parser\", \"lemmatizer\"]):\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/iamauser/Downloads/stack_overflow_ds/archive/Questions.csv', encoding='ISO-8859-1', usecols=['Title','Id'],nrows=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPatterns(langname):\n",
    "    return[\n",
    "        [{\"LOWER\":{\"REGEX\":'(%s\\d+\\.?\\d*.?\\d*)' % langname}}],\n",
    "        [{\"LOWER\":\"%s\"%langname},{\"TEXT\":{\"REGEX\":'(\\d+\\.?\\d*.?\\d*)'}}]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "# python_pat1 = [{\"LOWER\":\"python\"}]\n",
    "c_pattern = [{\"LOWER\":\"c\"}]\n",
    "c_plus = [{\"LOWER\":\"c++\"}]\n",
    "c_sharp = [{\"LOWER\":\"c#\"}]\n",
    "sql_pattern =[{\"LOWER\":\"sql\"}]\n",
    "go_pattern = [{\"LOWER\":\"go\", \"POS\":{\"NOT_IN\":['VERB']}}]\n",
    "go_pattern1 = [{\"LOWER\":\"golang\"}]\n",
    "pattern_list = getPatterns('python') + getPatterns('ruby') + getPatterns('java') + \\\n",
    "getPatterns('javascript') + getPatterns('js') + [c_pattern] + [c_plus] + [c_sharp] + [sql_pattern] +\\\n",
    "[go_pattern] + [go_pattern1]\n",
    "\n",
    "\n",
    "# matcher.add(\"PROGLANG\",getPatterns('SQL'))\n",
    "matcher.add(\"PROGLANG\",pattern_list)\n",
    "title_gen = (title for title in df['Title'])\n",
    "\n",
    "test_title_gen = (next(title_gen) for _ in range(100000)) #insert the dataset size in range\n",
    "\n",
    "matcher(nlp('python'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "        \n",
    "def get_training_entry(doc):\n",
    "    matched_elems = matcher(doc)\n",
    "#     print(len(dataset), end=\", \")\n",
    "    if len(matched_elems)!=0:\n",
    "        detections = [(doc[start:end].start_char,doc[start:end].end_char,doc.vocab.strings[hash_id]) for hash_id,start,end in matched_elems]\n",
    "        return doc.text, {'entities':detections}\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "_ = [dataset.append(t_entry) for t_entry in [get_training_entry(doc) for doc in nlp.pipe(test_title_gen)] if t_entry is not None]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E1010] Unable to set entity information for token 2 which is included in more than one span in entities, blocked, missing or outside.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-56ecf70ec110>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0ments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/image_env/lib/python3.7/site-packages/spacy/tokens/doc.pyx\u001b[0m in \u001b[0;36mspacy.tokens.doc.Doc.ents.__set__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/image_env/lib/python3.7/site-packages/spacy/tokens/doc.pyx\u001b[0m in \u001b[0;36mspacy.tokens.doc.Doc.set_ents\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E1010] Unable to set entity information for token 2 which is included in more than one span in entities, blocked, missing or outside."
     ]
    }
   ],
   "source": [
    "#Creating db for custom training \n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "db = DocBin()\n",
    "\n",
    "for text,annot in dataset:\n",
    "    doc = nlp.make_doc(text)\n",
    "    ents = []\n",
    "    for start,end,label in annot['entities']:\n",
    "        span = doc.char_span(start, end, label=label,alignment_mode=\"contract\")\n",
    "        if span is None:\n",
    "            print('skipping entry')\n",
    "        else:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents\n",
    "    db.add(doc)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_env",
   "language": "python",
   "name": "image_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
