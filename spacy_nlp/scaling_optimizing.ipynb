{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to process a large volume of text use:\n",
    "```python\n",
    "docs = list(nlp.pipe(LARGE_TEXT))\n",
    "            \n",
    "```\n",
    "It essentially creates a generator that yields tuples for optimized performance.\n",
    "We can also pass tuples also by selecting the `as_tuple=True`\n",
    "```python\n",
    "nlp.pipe(data, as_tuples=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is text1 10\n",
      "this is another one 12\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    (\"this is text1\", {\"id\":1, \"page_no\":10}),\n",
    "    (\"this is another one\",{\"id\":2, \"page_no\":12})\n",
    "]\n",
    "\n",
    "for doc, context in nlp.pipe(data, as_tuples=True):\n",
    "    print(doc.text, context[\"page_no\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoid Running the entire pipeline\n",
    "\n",
    "Sometimes we do not need the entire processing performed for us by the pipeline. \n",
    "If we just need to tokenize and create a doc, we use:\n",
    "```python\n",
    "\n",
    "nlp.make_doc(\"something goes here\")\n",
    "\n",
    "#temporally disable components\n",
    "with nlp.disable_pipes(\"tagger\", \"parser\"):\n",
    "    doc=nlp(text)\n",
    "    print(doc.ents)\n",
    "```\n",
    "The default pipeline functioning gets blocked after a single use after the block is exit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = [\"David Bowie\", \"Angela Merkel\", \"Lady Gaga\"]\n",
    "\n",
    "# Create a list of patterns for the PhraseMatcher\n",
    "patterns = list(nlp.pipe(people))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating And Training Models\n",
    "The steps of a training loop\n",
    "1. Loop for a number of times.\n",
    "2. Shuffle the training data.\n",
    "3. Divide the data into batches.\n",
    "4. Update the model for each batch.\n",
    "5. Save the updated model.\n",
    "\n",
    "\n",
    "<img src=\"https://course.spacy.io/training.png\">\n",
    "\n",
    "* Training data: Examples and their annotations.\n",
    "* Text: The input text the model should predict a label for.\n",
    "* Label: The label the model should predict.\n",
    "* Gradient: How to change the weights.\n",
    "\n",
    "#### template for updating previous models\n",
    "\n",
    "```python\n",
    "TRAINING_DATA = [\n",
    "    (\"How to preorder the iPhone X\", {\"entities\": [(20, 28, \"GADGET\")]})\n",
    "    # And many more examples...\n",
    "]\n",
    "\n",
    "# Loop for 10 iterations\n",
    "for i in range(10):\n",
    "    # Shuffle the training data\n",
    "    random.shuffle(TRAINING_DATA)\n",
    "    # Create batches and iterate over them\n",
    "    for batch in spacy.util.minibatch(TRAINING_DATA):\n",
    "        # Split the batch in texts and annotations\n",
    "        texts = [text for text, annotation in batch]\n",
    "        annotations = [annotation for text, annotation in batch]\n",
    "        # Update the model\n",
    "        nlp.update(texts, annotations)\n",
    "\n",
    "# Save the model\n",
    "nlp.to_disk(path_to_model)\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "#### template for setting up a new pipeline\n",
    "```python\n",
    "nlp = spacy.blank(\"en\")\n",
    "# Create blank entity recognizer and add it to the pipeline\n",
    "ner = nlp.create_pipe(\"ner\")\n",
    "nlp.add_pipe(ner)\n",
    "# Add a new label\n",
    "ner.add_label(\"GADGET\")\n",
    "\n",
    "# Start the training\n",
    "nlp.begin_training()\n",
    "# Train for 10 iterations\n",
    "for itn in range(10):\n",
    "    random.shuffle(examples)\n",
    "    # Divide examples into batches\n",
    "    for batch in spacy.util.minibatch(examples, size=2):\n",
    "        texts = [text for text, annotation in batch]\n",
    "        annotations = [annotation for text, annotation in batch]\n",
    "        # Update the model\n",
    "        nlp.update(texts, annotations)\n",
    "```\n",
    "\n",
    "\n",
    "### Problems with model updating and training\n",
    "1. Catastrophic Forgetting: If we only train with new data model can \"forget\" older examples. The best thing is to mix the older examples with the newer examples with each iteration of training.\n",
    "2. Models are only good for `local context` predictions. It can struggle if the decision is difficult to make based on the context. To avoid this labels should be fairly generic like:\n",
    "\"clothing\" is better than \"adult clothing\" , \"kid clothing\" etc.\n",
    "\n",
    "*brat, prodigy* for rapid data labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_dev",
   "language": "python",
   "name": "tf_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
