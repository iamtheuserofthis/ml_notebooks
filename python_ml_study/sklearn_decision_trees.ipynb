{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix=3,4,5,6\n",
    "\n",
    "class CombinedAttributeAdder(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, add_bedrooms_per_room=True):\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self,X,y=None):\n",
    "        rooms_per_household=X[:,rooms_ix]/X[:,households_ix]\n",
    "        population_per_household=X[:,population_ix]/X[:,households_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix]/X[:,rooms_ix]\n",
    "            return np.c_[X, rooms_per_household,\n",
    "                         population_per_household,\n",
    "                        bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household,\n",
    "                         population_per_household]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv('../data_for_ml/housing.csv')\n",
    "housing_y = housing['median_house_value']\n",
    "housing_x = housing.drop(columns = ['median_house_value'])\n",
    "housing_numeric_col = ['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
    "       'total_bedrooms', 'population', 'households', 'median_income']\n",
    "housing_cat_col = ['ocean_proximity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_transformers = Pipeline(steps=[\n",
    "    ('simple_imputer',SimpleImputer()),\n",
    "    ('attrib_adder', CombinedAttributeAdder()),\n",
    "    ('scaling', StandardScaler())\n",
    "])\n",
    "\n",
    "fullpipeline = ColumnTransformer([\n",
    "    ('num', numerical_transformers, housing_numeric_col),\n",
    "    ('cat', OneHotEncoder(), housing_cat_col)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running on whole first\n",
    "housing_pross = fullpipeline.fit_transform(housing_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr = DecisionTreeRegressor()\n",
    "dtr.fit(housing_pross, housing_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_data = housing_pross[:100]\n",
    "some_label = housing_y[:100]\n",
    "preds = dtr.predict(some_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_mse = mean_squared_error(some_label, preds)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing['income_cat'] = pd.cut(housing['median_income'],\n",
    "                    bins=[0.,1.5,3.0,4.5,6.0,np.inf],\n",
    "                    labels = [1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    0.350581\n",
       "2    0.318847\n",
       "4    0.176308\n",
       "5    0.114438\n",
       "1    0.039826\n",
       "Name: income_cat, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing['income_cat'].value_counts()/housing.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting with stratified shuffling the data\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_index,test_index in split.split(housing, housing['income_cat']):\n",
    "    strait_train_set = housing.loc[train_index] \n",
    "    strait_test_set  = housing.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    0.350533\n",
       "2    0.318798\n",
       "4    0.176357\n",
       "5    0.114583\n",
       "1    0.039729\n",
       "Name: income_cat, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strait_test_set['income_cat'].value_counts()/strait_test_set.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(dtr, housing_pross, housing_y,scoring=\"neg_mean_squared_error\", cv=10)\n",
    "\n",
    "\n",
    "#scores = cross_val_score(tree_reg, housing_prepared, housing_labels,\n",
    "#scoring=\"neg_mean_squared_error\", cv=10)\n",
    "#tree_rmse_scores = np.sqrt(-scores)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([119687.88503312,  72863.40731142,  83488.60047963,  76187.7107169 ,\n",
       "        89571.32929015,  79865.12472443,  67531.88473692, 102574.00709472,\n",
       "        95123.81881365,  72220.11020519])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Random Forest Regressor\n",
    "\n",
    "It uses ensemble of various trees and averages over their predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "forest_reg.fit(housing_pross, housing_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring the random forest with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_r_for = cross_val_score(forest_reg, housing_pross, housing_y,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-score_r_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([97558.90957667, 47698.75252643, 65492.87769314, 56616.68224428,\n",
       "       61311.08443543, 59576.08876532, 46483.25294373, 79553.79577879,\n",
       "       74393.68322745, 49224.93702995])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_rmse_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [97558.90957667 47698.75252643 65492.87769314 56616.68224428\n",
      " 61311.08443543 59576.08876532 46483.25294373 79553.79577879\n",
      " 74393.68322745 49224.93702995]\n",
      "Mean: 63791.00642211883\n",
      "Standard deviation 15330.119855342624\n"
     ]
    }
   ],
   "source": [
    "def display_scored(scores):\n",
    "    print(\"Scores:\" , scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation\", scores.std())\n",
    "display_scored(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Techniques For Fine-Tuning Models\n",
    "\n",
    "### Grid Search\n",
    "Fiddle with the hyperparameters manually, we find a great combination of hyperparameter values.\n",
    "\n",
    "### Randomized Search\n",
    "The grid search approach is fine when you are exploring relatively few combinations,\n",
    "like in the previous example, but when the hyperparameter search space is large, it is\n",
    "often preferable to use RandomizedSearchCV instead. This class can be used in much\n",
    "the same way as the GridSearchCV class, but instead of trying out all possible combi‐\n",
    "nations, it evaluates a given number of random combinations by selecting a random\n",
    "value for each hyperparameter at every iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid=[{'max_features': [2, 4, 6, 8],\n",
       "                          'n_estimators': [3, 10, 30]},\n",
       "                         {'bootstrap': [False], 'max_features': [2, 3, 4],\n",
       "                          'n_estimators': [3, 10]}],\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators':[3, 10, 30], 'max_features':[2, 4, 6, 8]},\n",
    "    {'bootstrap':[False], 'n_estimators':[3,10], 'max_features':[2,3,4]},\n",
    "]\n",
    "# n_estimators: The number of trees in the forest.\n",
    "#\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                          scoring = 'neg_mean_squared_error',\n",
    "                          return_train_score = True)\n",
    "grid_search.fit(housing_pross, housing_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 4, 'n_estimators': 30}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85665.87447465396 {'max_features': 2, 'n_estimators': 3}\n",
      "74426.31480774049 {'max_features': 2, 'n_estimators': 10}\n",
      "70335.76747652866 {'max_features': 2, 'n_estimators': 30}\n",
      "77690.3752731141 {'max_features': 4, 'n_estimators': 3}\n",
      "69225.60862305058 {'max_features': 4, 'n_estimators': 10}\n",
      "68043.8634421903 {'max_features': 4, 'n_estimators': 30}\n",
      "78447.75109243182 {'max_features': 6, 'n_estimators': 3}\n",
      "71404.96006910324 {'max_features': 6, 'n_estimators': 10}\n",
      "68644.53052182941 {'max_features': 6, 'n_estimators': 30}\n",
      "78284.03821698007 {'max_features': 8, 'n_estimators': 3}\n",
      "72259.70156933276 {'max_features': 8, 'n_estimators': 10}\n",
      "68972.3230549032 {'max_features': 8, 'n_estimators': 30}\n",
      "80294.22429324695 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "72873.1251990916 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "80723.20730028646 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "74063.47006288648 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "80833.48379070127 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "70815.58997365256 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "crves = grid_search.cv_results_\n",
    "for mean_score, params in zip(crves['mean_test_score'],crves['params']):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_feat = grid_search.best_estimator_.feature_importances_\n",
    "important_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrx = ['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
    "       'total_bedrooms', 'population', 'households', 'median_income',\n",
    "        'rooms_per_household','population_per_household','bedrooms_per_room']\n",
    "arrx.extend(\n",
    "    fullpipeline.named_transformers_['cat'].categories_[0].tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('longitude', 0.08020316816710923),\n",
       " ('latitude', 0.0761056571934163),\n",
       " ('housing_median_age', 0.04051633369611144),\n",
       " ('total_rooms', 0.023479810416991726),\n",
       " ('total_bedrooms', 0.021125626738222422),\n",
       " ('population', 0.023916943195943962),\n",
       " ('households', 0.01956604179520294),\n",
       " ('median_income', 0.3146426956888565),\n",
       " ('rooms_per_household', 0.06372173775252479),\n",
       " ('population_per_household', 0.09549174044917362),\n",
       " ('bedrooms_per_room', 0.07772014647366733),\n",
       " ('<1H OCEAN', 0.018062678146430786),\n",
       " ('INLAND', 0.13008751571195715),\n",
       " ('ISLAND', 0.0001449959036030404),\n",
       " ('NEAR BAY', 0.007498031979024085),\n",
       " ('NEAR OCEAN', 0.007716876691764648)]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "'median_income'\n",
    "'INLAND'\n",
    "\n",
    "These affect the prediction the most\n",
    "\n",
    "\"\"\"\n",
    "list(zip(arrx,important_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "array = np.array(['cat','cat','dog','dog','goat','goat','lion','cat','lion','dog','lion','goat'])\n",
    "array = array.reshape(-1,1)\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['cat', 'dog', 'goat', 'lion'], dtype='<U4')]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.transform(array).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_dev",
   "language": "python",
   "name": "tf_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
