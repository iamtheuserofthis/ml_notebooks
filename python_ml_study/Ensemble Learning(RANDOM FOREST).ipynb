{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "Random Forest is an ensemble of Decision Trees, generally trained via the bagging method (or sometimes pasting), typically with max_samples set to the size of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['data'], data['target'], test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_leaf_nodes=16, n_estimators=500, n_jobs=-1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "rnd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9298245614035088"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cap = rnd_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using grid search for optimizing parameters.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_parameters = [\n",
    "    {'n_estimators':[100, 150, 200, 250, 500], 'max_leaf_nodes':[4, 8, 16, 32], 'criterion':[\"gini\", \"entropy\"]},\n",
    "    {'n_estimators':[200, 250, 500], 'max_leaf_nodes':[4, 16, 32], 'criterion':[\"gini\", \"entropy\"]}\n",
    "]\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "gsearch = GridSearchCV(estimator=rfc, param_grid = grid_parameters, cv=3, verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 58 candidates, totalling 174 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=-1)]: Done 174 out of 174 | elapsed:   14.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid=[{'criterion': ['gini', 'entropy'],\n",
       "                          'max_leaf_nodes': [4, 8, 16, 32],\n",
       "                          'n_estimators': [100, 150, 200, 250, 500]},\n",
       "                         {'criterion': ['gini', 'entropy'],\n",
       "                          'max_leaf_nodes': [4, 16, 32],\n",
       "                          'n_estimators': [200, 250, 500]}],\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_leaf_nodes': 16, 'n_estimators': 200}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9298245614035088"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf1 = RandomForestClassifier(n_estimators=200, max_leaf_nodes=16, n_jobs=-1, criterion='entropy')\n",
    "rnd_clf1.fit(X_train, y_train)\n",
    "y_cap = rnd_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_cap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a few exceptions, a RandomForestClassifier has all the hyperparameters of a DecisionTreeClassifier (to control how trees are grown), plus all the hyperparameters of a BaggingClassifier to control the ensemble itself.\n",
    "\n",
    "__The Random Forest algorithm introduces extra randomness when growing trees instead of searching for the very best feature when splitting a node , it searches for the best feature among a random subset of features__. This results in a greater tree diversity, which (once again) trades a higher bias for a lower variance, generally yielding an overall better model.\n",
    "\n",
    "Random Forest:\n",
    "```python\n",
    "rnd_clf1 = RandomForestClassifier(n_estimators=200, max_leaf_nodes=16, n_jobs=-1, criterion='entropy')\n",
    "```\n",
    "\n",
    "Implementation RandomForest with bagging:\n",
    "```python\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(splitter=\"random\", max_leaf_nodes=16), n_estimators=500, max_samples=1.0, bootstrap=True, n_jobs=-1)\n",
    "\n",
    "```\n",
    "\n",
    "On each node we select the feature(s) and calulate the gini index for the node in question. How the feature(s) along with the output affects gini.\n",
    "\n",
    "|x1 |x2 |$\\hat{y}$|\n",
    "|---|---|---------|\n",
    "|2  |1  |0        |\n",
    "|3  |2  |0        |        \n",
    "|5  |1  |0        |                \n",
    "|4  |2  |1        |\n",
    "|5  |1  |1        |\n",
    "\n",
    "__condition 1: x1<5 : 0 else 1,__ \n",
    "\n",
    "gini index on that node1 => $1 -( \\frac{3}{3})^{2} -  (\\frac{0}{3})^{2} = 0$\n",
    "\n",
    "gini index on that node2 => $1 -( \\frac{2}{2})^{2} -  (\\frac{0}{2})^{2} = 0$\n",
    "\n",
    "GINI impurity for x1 = $\\frac{3}{3+2} \\times 0 + \\frac{2}{3+2} \\times 0 = 0$\n",
    "\n",
    "__condition 2: x2==1 : 0 else 1,__ \n",
    "\n",
    "gini index on that node1 => $1 - (\\frac{2}{3})^{2} -(\\frac{1}{3})^{2}= 0.445$\n",
    "\n",
    "gini index on that node2 => $1 - (\\frac{1}{2})^{2} -(\\frac{1}{2})^{2}= 0.5$\n",
    "\n",
    "GINI impurity for x2 = $\\frac{3}{3+2} \\times 0.445 + \\frac{2}{3+2} \\times 0.5 = 0.467$\n",
    "\n",
    "Hence condition 1 is prefered\n",
    "\n",
    "### proximity matrix?\n",
    "\n",
    "\n",
    "## Extra Tree Classifiers\n",
    "Growing a tree in a Random Forest, at each node only a random subset of the features is considered for splitting (as discussed earlier). It is possible to make trees even __more random by also using random thresholds__ for each feature rather than searching for the best possible thresholds.\n",
    "\n",
    "They are called Extremely Randomized Tree ensemble, Extra-tree for short.\n",
    "\n",
    "This trades more bias for a lower variance.\n",
    "\n",
    "It also makes Extra-Trees much faster to train than regular Random Forests since finding the best possible threshold for each feature at every node is one of the most time-consuming tasks of growing a tree.\n",
    "\n",
    "Feature importance can also for fetched in sklearn by feature_importances_ variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.467"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_dev",
   "language": "python",
   "name": "tf_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
