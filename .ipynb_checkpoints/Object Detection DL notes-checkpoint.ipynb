{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "\n",
    "1. Normalization techniques can decrease your model’s training time by a huge factor. \n",
    "\n",
    "2. It normalizes each feature so that they maintains the contribution of every feature, as some feature has higher numerical value than others. This way our network can be unbiased(to higher value features).\n",
    "\n",
    "3. It reduces Internal Covariate Shift. It is the change in the distribution of network activations due to the change in network parameters during training. To improve the training, we seek to reduce the internal covariate shift.\n",
    "\n",
    "4. Optimization occurs faster as exploding/diminishing gradients are reduced.\n",
    "\n",
    "5. It provides regularization also which is mostly an unintended side-effect.\n",
    "\n",
    "#### Batch Normalization\n",
    "Normalization across the minibatch. To learn the shift and scale that might be useful we add the $\\gamma, \\beta$ respectively.\n",
    "Calculated params:\n",
    "\n",
    "mini-batch mean, $\\mu_{B} = \\frac{1}{m} \\sum^{m}_{i=1} x_{i}$\n",
    "\n",
    "mini-batch var, $\\sigma^{2}_{B} = \\frac{1}{m}\\sum^{m}_{i=1} (x_{i}-\\mu_{B})^{2}$\n",
    "\n",
    "normalize, $\\widehat{x}_{i} = \\frac{x_{i}-\\mu{B}}{\\sqrt{\\sigma^{2}_{B}+\\epsilon}}$\n",
    "\n",
    "scale and shift, $y_{i} = \\gamma\\widehat{x_{i}}+\\beta = BN_{\\gamma,\\beta(x_{i})}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display\n",
    "from seaborn import color_palette\n",
    "import cv2\n",
    "_BATCH_NORM_DECAY = 0.9\n",
    "_BATCH_NORM_EPSILON = 1e-05\n",
    "_LEAKY_RELU = 0.1\n",
    "_ANCHORS = [(10, 13), (16, 30), (33, 23),\n",
    "            (30, 61), (62, 45), (59, 119),\n",
    "            (116, 90), (156, 198), (373, 326)]\n",
    "_MODEL_SIZE = (416, 416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch norm\n",
    "def batch_norm(inputs, training, data_format):\n",
    "    return tf.layers.batch_normalization(inputs=inputs, \n",
    "                                         axis=1 if data_format == 'channels_first' else 3,\n",
    "                                         momentum=_BATCH_NORM_DECAY,\n",
    "                                         epsilon=_BATCH_NORM_EPSILON,\n",
    "                                         scale=True, training=training\n",
    "                                        )\n",
    "\n",
    "\n",
    "def fixed_padding(inputs, kernel_size, data_format):\n",
    "    pad_total = kernel_size - 1\n",
    "    pad_beg = pad_total//2\n",
    "    pad_end = pad_total - pad_beg\n",
    "    \n",
    "    if data_format == 'channels_first':\n",
    "        padded_inputs = tf.pad(inputs,[[0,0],[0,0],\n",
    "                                      [pad_beg, pad_end],\n",
    "                                      [pad_beg, pad_end]])\n",
    "    else:\n",
    "        padded_inputs = tf.pad(inputs,[[0,0],[pad_beg, pad_end],\n",
    "                                      [pad_beg, pad_end], [0,0]])\n",
    "    return padded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "paddings = tf.constant([[1, 1], [2, 2]])\n",
    "# paddings constants describe the amount of padding, here\n",
    "# [[top_padding, bottom_padding],[left_padding, right_padding]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "[[1 1]\n",
      " [2 2]]\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 1 2 3 0 0]\n",
      " [0 0 4 5 6 0 0]\n",
      " [0 0 0 0 0 0 0]]\n",
      "[[2 1 1 2 3 3 2]\n",
      " [2 1 1 2 3 3 2]\n",
      " [5 4 4 5 6 6 5]\n",
      " [5 4 4 5 6 6 5]]\n",
      "[2, 2]\n",
      "[[1]\n",
      " [1]\n",
      " [2]\n",
      " [2]]\n",
      "[[1 2 3 1 2 3]\n",
      " [4 5 6 4 5 6]\n",
      " [1 2 3 1 2 3]\n",
      " [4 5 6 4 5 6]]\n",
      "[1 4]\n",
      "[2 5]\n",
      "[3 6]\n",
      "[2 2 0 2 2]\n",
      "[2 2 1]\n",
      "[[[ 1  2]\n",
      "  [ 3  4]]\n",
      "\n",
      " [[ 4  3]\n",
      "  [ 9  8]]\n",
      "\n",
      " [[ 9  8]\n",
      "  [ 0 10]]] shape [3 2 2]\n",
      "[[2 2]\n",
      " [1 2]]\n",
      "[[1 1]\n",
      " [1 1]\n",
      " [0 1]]\n",
      "[[1 1]\n",
      " [0 0]\n",
      " [0 1]]\n",
      "comp section\n",
      "[6 7]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "    print(t.eval())\n",
    "    print(paddings.eval())\n",
    "    print(tf.pad(t, paddings, \"CONSTANT\").eval())\n",
    "#    print(tf.pad(t, paddings, \"REFLECT\").eval())\n",
    "    print(tf.pad(t, paddings, \"SYMMETRIC\").eval())\n",
    "    print(paddings.get_shape().as_list())\n",
    "    print(tf.reshape(paddings, [-1,1]).eval())  \n",
    "    x = tf.range(10, dtype=tf.float32)\n",
    "    y = tf.range(10, dtype=tf.float32)\n",
    "    x_offset, y_offset = tf.meshgrid(x,y)\n",
    "    x_offset = tf.reshape(x_offset, (-1,1))\n",
    "    y_offset = tf.reshape(y_offset, (-1,1))\n",
    "    # changes rows to columns, columns remain columns\n",
    "    \n",
    "    x_y_offset = tf.concat([x_offset, y_offset], axis=-1)\n",
    "    #print(x_y_offset.eval())\n",
    "    a = tf.constant([[1,2,3],[4,5,6]], tf.int32)\n",
    "    b = tf.constant([2,2], tf.int32)\n",
    "    print(tf.tile(a,b).eval())\n",
    "    [print(i.eval()) for i in tf.unstack(a, axis=1)]\n",
    "    B = tf.constant([[2, 20, 30, 3, 6], [3, 11, 16, 1, 8],\n",
    "                 [14, 45, 23, 5, 27]])\n",
    "    d3 = tf.constant([[[1,2],[3,4]],[[4,3],[9,8]],[[9,8],[0,10]]])\n",
    "    \n",
    "    #this calculates max index along all cols in the row\n",
    "    print(tf.argmax(B, axis=0).eval())\n",
    "    \n",
    "    #this calculates max index along all rows in each col\n",
    "    print(tf.argmax(B, axis=1).eval())\n",
    "    print(d3.eval(), 'shape',tf.shape(d3).eval())\n",
    "    print(tf.argmax(d3, axis=0).eval())\n",
    "    print(tf.argmax(d3, axis=1).eval())\n",
    "    print(tf.argmax(d3, axis=2).eval())\n",
    "    print('comp section')\n",
    "    xs = tf.constant([1,2,3,4,5,6,7], dtype=tf.int32)\n",
    "    print(tf.boolean_mask(xs,xs>5).eval())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_fixed_padding(inputs, filters, kernel_size,  data_format, strides=1):\n",
    "    if strides>1:\n",
    "        inputs = fixed_padding(inputs, kernel_size, data_format)\n",
    "    return tf.layers.conv2d(inputs=inputs, \n",
    "                            filters=filters, \n",
    "                            kernel_size=kernel_size,\n",
    "                            strides=strides,\n",
    "                           padding=('SAME' if strides == 1 else 'VALID'),\n",
    "                           use_bias=False, data_format=data_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction: Darknet-53\n",
    "It does not has the layers required for classification at the end i.e.  Avgpool, Connected, softmax since its just used for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def darknet53_residual_block(inputs, filters, training, data_format, strides=1):\n",
    "    shortcut = inputs\n",
    "\n",
    "    inputs = conv2d_fixed_padding(\n",
    "        inputs, filters=filters, kernel_size=1, strides=strides,\n",
    "        data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    inputs = conv2d_fixed_padding(\n",
    "        inputs, filters= 2 * filters, kernel_size=3, strides=strides,\n",
    "        data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    inputs += shortcut\n",
    "\n",
    "    return inputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def darknet53(inputs, training, data_format):\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=32, kernel_size=3, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    \n",
    "    inputs = conv2d_fixed_padding(inputs, filters=64, kernel_size=3, strides=2, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format= data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    \n",
    "    inputs = darknet53_residual_block(inputs, filters=32, training=training, data_format=data_format)\n",
    "    inputs =  conv2d_fixed_padding(inputs, filters=128, kernel_size=3, strides=2, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training,data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    \n",
    "    \n",
    "    for k in range(2):\n",
    "    \n",
    "        inputs = darknet53_residual_block(inputs, filters=64, training=training, data_format=data_format)\n",
    "    \n",
    "        \n",
    "    inputs = conv2d_fixed_padding(inputs, filters=256, kernel_size=3, strides=2, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "    for _ in range(8):\n",
    "        \n",
    "        inputs = darknet53_residual_block(inputs, filters=128, training=training, data_format=data_format)\n",
    "        \n",
    "    route1 = inputs\n",
    "        \n",
    "    inputs = conv2d_fixed_padding(inputs, filters=512, kernel_size=3, strides=2, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    \n",
    "    for _ in range(8):\n",
    "        inputs = darknet53_residual_block(inputs, filters=256, training=training, data_format=data_format)\n",
    "        \n",
    "    route2 = inputs\n",
    "        \n",
    "    inputs = conv2d_fixed_padding(inputs, filters=1024, kernel_size=3, strides=2, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    \n",
    "    for _ in range(4):\n",
    "        inputs = darknet53_residual_block(inputs, filters=512, training=training, data_format=data_format)\n",
    "\n",
    "    return route1, route2, inputs       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1x1 convolution layer usage\n",
    "\n",
    "A 1×1 convolutional layer can be used that offers a channel-wise pooling, often called feature map pooling or a projection layer. \n",
    "\n",
    "This simple technique can be used for dimensionality reduction, decreasing the number of feature maps whilst retaining their salient features. \n",
    "\n",
    "It can also be used directly to create a one-to-one projection of the feature maps to pool features across channels or to increase the number of feature maps, such as after traditional pooling layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_convolution_block(inputs, filters, training, data_format):\n",
    "    \n",
    "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    \n",
    "    inputs = conv2d_fixed_padding(inputs, filters= 2 * filters, kernel_size=3, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    \n",
    "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    \n",
    "    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    \n",
    "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    \n",
    "    route = inputs\n",
    "    \n",
    "    inputs = conv2d_fixed_padding(inputs, filters= 2 * filters, kernel_size=3, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    \n",
    "    return route, inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DETECTION LAYERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_layers(inputs, n_classes, anchors, img_size, data_format):\n",
    "    n_anchors = len(anchors)\n",
    "    inputs = tf.layers.conv2d(inputs, filters= n_anchors * (5+n_classes), kernel_size=1, \n",
    "                             strides=1, use_bias=True, data_format=data_format)\n",
    "    print('yolo first layer working')\n",
    "    shape = inputs.get_shape().as_list()\n",
    "    grid_shape = shape[2:4] if data_format == 'channels_first' else shape[1:3]\n",
    "    \n",
    "    if data_format == 'channels_first':\n",
    "        inputs = tf.reshape(inputs, [0,2,3,1])\n",
    "    \n",
    "    \n",
    "    inputs = tf.reshape(inputs, [-1, n_anchors*grid_shape[0]*grid_shape[1], 5+n_classes])\n",
    "    strides = (img_size[0]//grid_shape[0], img_size[1]//grid_shape[1])\n",
    "    print('reshaping done')\n",
    "    box_centers, box_shapes, confidence, classes = tf.split(inputs, [2,2,1,n_classes], axis=-1)\n",
    "    print('splitting done')\n",
    "    x = tf.range(grid_shape[0], dtype=tf.float32)\n",
    "    y = tf.range(grid_shape[1], dtype=tf.float32)\n",
    "    x_offset, y_offset = tf.meshgrid(x,y)\n",
    "    x_offset = tf.reshape(x_offset, (-1,1))\n",
    "    y_offset = tf.reshape(y_offset, (-1,1))\n",
    "    x_y_offset = tf.concat([x_offset, y_offset], axis=-1)\n",
    "    x_y_offset = tf.tile(x_y_offset, [1, n_anchors])\n",
    "    x_y_offset = tf.reshape(x_y_offset, [1, -1, 2])\n",
    "    box_centers = tf.nn.sigmoid(box_centers)\n",
    "    box_centers = (box_centers + x_y_offset) * strides\n",
    "    \n",
    "    anchors = tf.tile(anchors, [grid_shape[0] * grid_shape[1],1])\n",
    "    box_shapes = tf.exp(box_shapes) * tf.to_float(anchors)\n",
    "    confidence = tf.nn.sigmoid(confidence)\n",
    "    classes = tf.nn.sigmoid(classes)\n",
    "    inputs = tf.concat([box_centers, box_shapes, confidence, classes], axis=-1)\n",
    "    \n",
    "    return inputs\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(inputs, out_shape, data_format):\n",
    "    \"\"\"\n",
    "    \n",
    "    inputs: tensor of the inputs\n",
    "    out_shape: the shape to which the inputs are to be shaped\n",
    "   \n",
    "    \"\"\"\n",
    "    if data_format == 'channels_first':\n",
    "        inputs = tf.transpose(inputs, [0,2,3,1])\n",
    "        new_height = out_shape[3]\n",
    "        new_width = out_shape[2]\n",
    "    \n",
    "    else:\n",
    "        new_height = out_shape[2]\n",
    "        new_width = out_shape[1]\n",
    "    \n",
    "    \"\"\"\n",
    "    changes the dimensions of the image based on the new dimensions \n",
    "    provided\n",
    "    \"\"\"\n",
    "    inputs = tf.image.resize_nearest_neighbor(inputs, (new_height, new_width))\n",
    "    \n",
    "    if data_format == 'channel_first':\n",
    "        inputs = tf.transpose(inputs, [0,3,1,2])\n",
    "        \n",
    "    return inputs\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-max suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_boxes(inputs):\n",
    "    \n",
    "    center_x, center_y, width, height, confidence,classes = tf.split(inputs,[1,1,1,1,1,-1], axis=-1)\n",
    "    \n",
    "    top_left_x = center_x - width/2\n",
    "    top_left_y = center_y - height/2\n",
    "    bottom_right_x = center_x + width/2\n",
    "    bottom_right_y = center_y + height/2\n",
    "    \n",
    "    boxes = tf.concat([top_left_x, top_left_y, bottom_right_x, bottom_right_y, confidence, classes], axis=-1)\n",
    "    \n",
    "    return boxes\n",
    "\n",
    "def non_max_suppression(inputs, n_classes, max_output_size, iou_threshold, confidence_threshold):\n",
    "    \n",
    "    batch = tf.unstack(inputs)\n",
    "    boxes_dicts = []\n",
    "    \n",
    "    for boxes in batch:\n",
    "        boxes = tf.boolean_mask(boxes, boxes[:,4] > confidence_threshold)\n",
    "        classes = tf.argmax(boxes[:, 5:], axis=-1)\n",
    "        boxes_dict = {}\n",
    "        for cls in range(n_classes):\n",
    "            mask = tf.equal(boxes[:,5], cls)\n",
    "            mask_shape = mask.get_shape()\n",
    "            \n",
    "            if mask_shape != 0:\n",
    "                class_boxes = tf.boolean_mask(boxes,  mask)\n",
    "                boxes_coords, boxes_conf_scores,_ = tf.split(class_boxes, [4,1,-1], axis=-1)\n",
    "                boxes_conf_scores = tf.reshape(boxes_conf_scores, [-1])\n",
    "                \n",
    "                # prunes away boxes with high intersection-over-union score\n",
    "                indices = tf.image.non_max_suppression(boxes_coords, \n",
    "                                                       boxes_conf_scores, \n",
    "                                                       max_output_size,\n",
    "                                                       iou_threshold)\n",
    "                class_boxes = tf.gather(class_boxes,indices)\n",
    "                boxes_dict[cls] = class_boxes[:,:5]\n",
    "        boxes_dicts.append(boxes_dict)\n",
    "    return boxes_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolo_v3:\n",
    "    \n",
    "    def __init__(self, n_classes, model_size, max_output_size, \n",
    "                 iou_threshold, confidence_threshold, data_format=None):\n",
    "        if not data_format:\n",
    "            if tf.test.is_built_with_cuda():\n",
    "                data_format = 'channels_first'\n",
    "            else:\n",
    "                data_format = 'channels_last'\n",
    "                \n",
    "        self.n_classes = n_classes\n",
    "        self.model_size = model_size\n",
    "        self.max_output_size = max_output_size\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.data_format = data_format\n",
    "        \n",
    "    def __call__(self, inputs, training):\n",
    "        with tf.variable_scope('yolo_v3_model'):\n",
    "            if self.data_format ==  'channels_first':\n",
    "                inputs = tf.transpose(inputs, [0,3,1,2])\n",
    "            \n",
    "            inputs = inputs/255\n",
    "            \n",
    "            \n",
    "            # -------------------------------sec_1-------------------------------\n",
    "            # running the darknet53 to extract features from multiple sections of nn\n",
    "            route1, route2, inputs = darknet53(inputs, \n",
    "                                               training=training,\n",
    "                                               data_format=self.data_format\n",
    "                                              )\n",
    "            \n",
    "            \n",
    "            \n",
    "            route, inputs = yolo_convolution_block(inputs,\n",
    "                                                  training=training,\n",
    "                                                   filters=512,\n",
    "                                                  data_format=self.data_format)\n",
    "            print('completed out 1')\n",
    "            # result0\n",
    "            detect1 = yolo_layers(inputs, \n",
    "                                  n_classes=self.n_classes,\n",
    "                                  anchors=_ANCHORS[6:9],\n",
    "                                  img_size=self.model_size,\n",
    "                                  data_format=self.data_format\n",
    "                                 )\n",
    "            print('completed out detect1')\n",
    "            \n",
    "            inputs = conv2d_fixed_padding(route, filters=256, kernel_size=1,\n",
    "                                         data_format=self.data_format)\n",
    "            inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "            upsample_size = route2.get_shape().as_list()\n",
    "            \n",
    "            \n",
    "            # size of the inputs decreses as we go deeper in the network\n",
    "            # we upsample it for concatenation with the result of the \n",
    "            # intermediary stages\n",
    "            inputs = upsample(inputs, \n",
    "                              out_shape=upsample_size,\n",
    "                              data_format=self.data_format)\n",
    "            axis = 1 if self.data_format == 'channels_first' else 3\n",
    "            \n",
    "            # concating the inputs and intermediary result\n",
    "            inputs = tf.concat([inputs, route2], axis=axis)\n",
    "            \n",
    "            route, inputs = yolo_convolution_block(inputs,\n",
    "                                                   filters=256,\n",
    "                                                   training=training,\n",
    "                                                   data_format=self.data_format)\n",
    "           \n",
    "            # result1\n",
    "            detect2 = yolo_layers(inputs, n_classes=self.n_classes,\n",
    "                                 anchors = _ANCHORS[3:6],\n",
    "                                 img_size = self.model_size,\n",
    "                                 data_format=self.data_format)\n",
    "            \n",
    "            inputs = conv2d_fixed_padding(route, filters=128, \n",
    "                                          kernel_size=1,\n",
    "                                          data_format=self.data_format)\n",
    "            inputs = batch_norm(inputs, training=training, data_format=self.data_format)\n",
    "            inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "            upsample_size = route1.get_shape().as_list()\n",
    "            inputs = upsample(inputs, out_shape=upsample_size, data_format=self.data_format)\n",
    "            inputs = tf.concat([inputs, route1], axis=axis)\n",
    "            route, inputs = yolo_convolution_block(inputs, \n",
    "                                                   filters=128,\n",
    "                                                   training=training,\n",
    "                                                   data_format=self.data_format\n",
    "                                                  )\n",
    "            # result2\n",
    "            detect3 = yolo_layers(inputs, n_classes,\n",
    "                                anchors=_ANCHORS[0:3],\n",
    "                                img_size=self.model_size,\n",
    "                                data_format=self.data_format)\n",
    "            \n",
    "            \n",
    "            # combining final results\n",
    "            \"\"\"\n",
    "            \n",
    "            Detection layers\n",
    "\n",
    "            Yolo has 3 detection layers, \n",
    "            that detect on 3 different scales using respective anchors. \n",
    "            For each cell in the feature map the detection layer \n",
    "            predicts n_anchors * (5 + n_classes) values using 1x1 convolution. \n",
    "            For each scale we have n_anchors = 3. 5 + n_classes means that \n",
    "            respectively to each of 3 anchors we are going to predict \n",
    "            4 coordinates of the box, its confidence score \n",
    "            (the probability of containing an object) and class probabilities.\n",
    "\n",
    "            \"\"\"\n",
    "            inputs = tf.concat([detect1, detect2, detect3], axis=1)\n",
    "            inputs = build_boxes(inputs)\n",
    "            \n",
    "            boxes_dicts = non_max_suppression(inputs,\n",
    "                                              n_classes=self.n_classes,\n",
    "                                              max_output_size=self.max_output_size,\n",
    "                                              iou_threshold=self.iou_threshold,\n",
    "                                              confidence_threshold=self.confidence_threshold)\n",
    "            \n",
    "            return boxes_dicts\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(img_names, model_size):\n",
    "    imgs = []\n",
    "\n",
    "    for img_name in img_names:\n",
    "        img = Image.open(img_name)\n",
    "        img = img.resize(size=model_size)\n",
    "        img = np.array(img, dtype=np.float32)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        imgs.append(img)\n",
    "\n",
    "    imgs = np.concatenate(imgs)\n",
    "\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_class_names(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        class_names = f.read().splitlines()\n",
    "    return class_names\n",
    "\n",
    "def draw_boxes(img_names, boxes_dicts, class_names, model_size):\n",
    "    \n",
    "    colors = ((np.array(color_palette(\"hls\",80))*255)).astype(np.uint8)\n",
    "    for num, img_name, boxes_dict in zip(range(len(img_names)), img_names, boxes_dicts):\n",
    "        img = Image.open(img_name)\n",
    "        draw = ImageDraw(img)\n",
    "        font = ImageFont.truetype(font='../input/futur.ttf',\n",
    "                                 size= (img.size[0]+img.size[1])//100)\n",
    "        resize_factor = (img.size[0]/model_size[0], img.size[1].model_size[1])\n",
    "        \n",
    "        for cls in range(len(class_names)):\n",
    "            boxes = boxes_dict[cls]\n",
    "            \n",
    "            if np.size(boxes) != 0:\n",
    "                color = colors[cls]\n",
    "                \n",
    "                for box in boxes:\n",
    "                    xy, confidence = box[:4], box[4]\n",
    "                    xy = [xy[i]*resize_factor[i%2] for i in range(4)]\n",
    "                    x0,y0 = xy[0], xy[1]\n",
    "                    thickness = (img.size[0]+ img.size[1])//200\n",
    "                    \n",
    "                    for t in np.linsapce(0, 1, thickness):\n",
    "                        xy[0], xy[1] = xy[0]+t , xy[1]+t\n",
    "                        xy[2], xy[3] = xy[2]-t, xy[3]-t\n",
    "                        \n",
    "                        draw.rectangle(xy, outline=tuple(color))\n",
    "                    \n",
    "                    text = '{} {:.1f}%'.format(class_names[cls], confidence*100)\n",
    "                    text_size = draw.textsize(test, font=font)\n",
    "                    draw.rectangle(\n",
    "                        [x0, y0 - text_size[1], x[0]+text_size[0], y0],\n",
    "                        fill=tuple(color))\n",
    "                    \n",
    "                    draw.text((x0,y0-text_size[1]), text, fill='black', font=font)\n",
    "        display(img)\n",
    "                        \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(9).reshape(3,3)\n",
    "b = np.arange(9).reshape(3,3)\n",
    "print(b.shape)\n",
    "# expanding dimensions is required for concatenation\n",
    "# without it the elements/axes are concatenated of a tensor\n",
    "# not the tensors themselves\n",
    "a1 = np.expand_dims(a, axis=0)\n",
    "b1 = np.expand_dims(b, axis=0)\n",
    "np.concatenate([a1,b1])\n",
    "eg_str = 'a\\nb\\nc\\n'\n",
    "eg_str.splitlines() #breaks at newlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(variables, file_name):\n",
    "\n",
    "    with open(file_name, \"rb\") as f:\n",
    "        # Skip first 5 values containing irrelevant info\n",
    "        np.fromfile(f, dtype=np.int32, count=5)\n",
    "        weights = np.fromfile(f, dtype=np.float32)\n",
    "\n",
    "        assign_ops = []\n",
    "        ptr = 0\n",
    "\n",
    "        # Load weights for Darknet part.\n",
    "        # Each convolution layer has batch normalization.\n",
    "        for i in range(52):\n",
    "            conv_var = variables[5 * i]\n",
    "            gamma, beta, mean, variance = variables[5 * i + 1:5 * i + 5]\n",
    "            batch_norm_vars = [beta, gamma, mean, variance]\n",
    "\n",
    "            for var in batch_norm_vars:\n",
    "              \n",
    "                shape = var.shape.as_list()\n",
    "                num_params = np.prod(shape)\n",
    "                var_weights = weights[ptr:ptr + num_params].reshape(shape)\n",
    "                ptr += num_params\n",
    "                assign_ops.append(tf.assign(var, var_weights))\n",
    "\n",
    "            shape = conv_var.shape.as_list()\n",
    "          \n",
    "            num_params = np.prod(shape)\n",
    "            var_weights = weights[ptr:ptr + num_params].reshape(\n",
    "                (shape[3], shape[2], shape[0], shape[1]))\n",
    "            var_weights = np.transpose(var_weights, (2, 3, 1, 0))\n",
    "            ptr += num_params\n",
    "            assign_ops.append(tf.assign(conv_var, var_weights))\n",
    "\n",
    "        # Loading weights for Yolo part.\n",
    "        # 7th, 15th and 23rd convolution layer has biases and no batch norm.\n",
    "        \n",
    "        \n",
    "        ranges = [range(0, 6), range(6, 13), range(13, 20)]\n",
    "        unnormalized = [6, 13, 20]\n",
    "        print(variables)\n",
    "        for j in range(3):\n",
    "            for i in ranges[j]:\n",
    "                print('i: %s, j:%s' %(i,j))\n",
    "                current = 52 * 5 + 5 * i + j * 2\n",
    "                \n",
    "                conv_var = variables[current]\n",
    "                gamma, beta, mean, variance =  \\\n",
    "                    variables[current + 1:current + 5]\n",
    "                batch_norm_vars = [beta, gamma, mean, variance]\n",
    "                \n",
    "                for var in batch_norm_vars:\n",
    "                    shape = var.shape.as_list()\n",
    "                    num_params = np.prod(shape)\n",
    "                    var_weights = weights[ptr:ptr + num_params].reshape(shape)\n",
    "                    ptr += num_params\n",
    "                    assign_ops.append(tf.assign(var, var_weights))\n",
    "                \n",
    "                shape = conv_var.shape.as_list()\n",
    "                num_params = np.prod(shape)\n",
    "                print('%s' % shape)\n",
    "                var_weights = weights[ptr:ptr + num_params].reshape(\n",
    "                    (shape[3], shape[2], shape[0], shape[1]))\n",
    "                print('reaching here')\n",
    "                var_weights = np.transpose(var_weights, (2, 3, 1, 0))\n",
    "                ptr += num_params\n",
    "                assign_ops.append(tf.assign(conv_var, var_weights))\n",
    "                \n",
    "            bias = variables[52 * 5 + unnormalized[j] * 5 + j * 2 + 1]\n",
    "            shape = bias.shape.as_list()\n",
    "            num_params = np.prod(shape)\n",
    "            var_weights = weights[ptr:ptr + num_params].reshape(shape)\n",
    "            ptr += num_params\n",
    "            assign_ops.append(tf.assign(bias, var_weights))\n",
    "\n",
    "            conv_var = variables[52 * 5 + unnormalized[j] * 5 + j * 2]\n",
    "            shape = conv_var.shape.as_list()\n",
    "            num_params = np.prod(shape)\n",
    "            var_weights = weights[ptr:ptr + num_params].reshape(\n",
    "                (shape[3], shape[2], shape[0], shape[1]))\n",
    "            var_weights = np.transpose(var_weights, (2, 3, 1, 0))\n",
    "            ptr += num_params\n",
    "            assign_ops.append(tf.assign(conv_var, var_weights))\n",
    "\n",
    "    return assign_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = '/home/iamtheuserofthis/untagged_data/yolo_test'\n",
    "image_paths= []\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    image_paths.append(os.path.join(path, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed out 1\n",
      "yolo first layer working\n",
      "reshaping done\n",
      "splitting done\n",
      "completed out detect1\n",
      "yolo first layer working\n",
      "reshaping done\n",
      "splitting done\n",
      "yolo first layer working\n",
      "reshaping done\n",
      "splitting done\n",
      "i: 0, j:0\n",
      "[1, 1, 1024, 512]\n",
      "reaching here\n",
      "i: 1, j:0\n",
      "[3, 3, 512, 1024]\n",
      "reaching here\n",
      "i: 2, j:0\n",
      "[1, 1, 1024, 512]\n",
      "reaching here\n",
      "i: 3, j:0\n",
      "[3, 3, 512, 1024]\n",
      "reaching here\n",
      "i: 4, j:0\n",
      "[1, 1, 1024, 512]\n",
      "reaching here\n",
      "i: 5, j:0\n",
      "[3, 3, 512, 1024]\n",
      "reaching here\n",
      "i: 6, j:1\n",
      "[1, 1, 512, 256]\n",
      "reaching here\n",
      "i: 7, j:1\n",
      "[256]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-4de091ec156b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0myolo_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/iamtheuserofthis/python_workspace/data_for_ml/yolov3.weights'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mmodel_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'yolo_v3_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0massign_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myolo_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-48-21cfcbe47ef2>\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(variables, file_name)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 var_weights = weights[ptr:ptr + num_params].reshape(\n\u001b[0;32m---> 61\u001b[0;31m                     (shape[3], shape[2], shape[0], shape[1]))\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'reaching here'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mvar_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = len(image_paths)\n",
    "batch = load_images(image_paths, model_size=_MODEL_SIZE)\n",
    "class_names = load_class_names(os.path.join('/home/iamtheuserofthis/untagged_data/','coco.names'))\n",
    "n_classes = len(class_names)\n",
    "max_output_size = 10\n",
    "iou_threshold = 0.5\n",
    "confidence_threshold = 0.5\n",
    "\n",
    "model = Yolo_v3(n_classes=n_classes, model_size=_MODEL_SIZE,\n",
    "               max_output_size=max_output_size,\n",
    "               iou_threshold=iou_threshold,\n",
    "               confidence_threshold=confidence_threshold)\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, [batch_size, 416, 416, 3])\n",
    "detections = model(inputs, training=False)\n",
    "\n",
    "yolo_weights = '/home/iamtheuserofthis/python_workspace/data_for_ml/yolov3.weights'\n",
    "model_vars = tf.global_variables(scope='yolo_v3_model')\n",
    "assign_ops = load_weights(model_vars, yolo_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_env_kernel",
   "language": "python",
   "name": "image_env_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
