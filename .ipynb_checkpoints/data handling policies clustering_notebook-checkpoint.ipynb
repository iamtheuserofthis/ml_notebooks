{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type of clustering\n",
    "\n",
    "#### Based On How We Group\n",
    "\n",
    "1. Hard Clustering - In hard clustering, each data point either belongs to a cluster completely or not.\n",
    "\n",
    "2. Soft Clustering - In soft clustering, instead of putting each data point into a separate cluster, a probability or likelihood of that data point to be in those clusters is assigned.\n",
    "\n",
    "### Clustering Algorithms\n",
    "\n",
    "Every methodology follows a different set of rules for defining the ‘similarity’ among data points.Every methodology follows a different set of rules for defining the ‘similarity’ among data points.\n",
    "\n",
    "#### 1. Connectivity Models\n",
    "**Key Idea**: The data points closer in data space exhibit more similarity to each other than the data points lying farther away\n",
    "\n",
    "##### Approaches\n",
    "1. Start with classifying all data points into separate clusters & then aggregating them as the distance decreases.\n",
    "2. All data points are classified as a single cluster and then partitioned as the distance increases.\n",
    "\n",
    "###### Drawbacks\n",
    "* Simple to understand but lacks scalability.\n",
    "\n",
    "\n",
    "#### 2. Centroid Models\n",
    "**Key Idea***: The notion of similarity is derived by the closeness of a data point to the centroid of the clusters. It is iterative by nature therefore addresses the problem of scalability.\n",
    "\n",
    "###### Drawbacks\n",
    "* The number of cluster must be known beforehand therefore knowledge of the data at hand is expected reasonably.\n",
    "\n",
    "\n",
    "#### 3. Distribution Models\n",
    "**Key Idea**: Based on the notion of how probable is it that all data points in the cluster belong to the same distribution (e.g. normal distribution, or gaussian dist).\n",
    "\n",
    "###### Drawbacks\n",
    "* Suffers from overfitting.\n",
    "\n",
    "#### 4. Density Models\n",
    "**Key Idea**: Searches the data space for areas of varied density of data points in the data space. It isolates various different density regions and assign the data points within these regions in the same cluster.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K- Means Clustering\n",
    "* Iterative Clustering. Following are the steps involved in the clustering using the k-means.\n",
    "* It is a hard clustering, i.e one data-point is the member of one and only one cluster. That is there is no way of quantifying the relationship of one data-point to multiple clusters.\n",
    "\n",
    "\n",
    "#### Inertia of dataset:\n",
    "The amount of inertia in a data set is a multivariate measure of the amount of variation in a data set.\n",
    "\n",
    "The K-means algorithm aims to choose centroids that minimise the inertia, or within-cluster sum-of-squares criterion.\n",
    "\n",
    "Inertia can be recognized as a measure of how internally coherent clusters are. It suffers from various drawbacks:\n",
    "\n",
    "* Inertia makes the assumption that clusters are `convex and isotropic`, which is not always the case. It responds poorly to elongated clusters, or manifolds with irregular shapes.\n",
    "\n",
    "* Inertia is not a normalized metric: we just know that lower values are better and zero is optimal. But in very high-dimensional spaces, Euclidean distances tend to become inflated (this is an instance of the so-called “curse of dimensionality”). Running a dimensionality reduction algorithm such as Principal component analysis (PCA) prior to k-means clustering can alleviate this problem and speed up the computations.\n",
    "\n",
    "** A convex shape is the opposite of a concave shape. It curves outward, and its middle is thicker than its edges.\n",
    "\n",
    "** isotorpic is having a physical property which has the same value when measured in different directions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "x = np.random.randint(1,30,size=10)\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/639388c2cbc2120a14dcf466e85730eb8be498bb/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 15, 16] [[14], [10], [4]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[14, 12, 13, 15, 16], [10, 7, 8, 9, 11], [4, 1, 2, 3, 5, 6]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# considering the numberline case, i.e. single feature\n",
    "k = 3\n",
    "def getKSeedArr(K, obArr:list, empArr:list = list()):\n",
    "# selection of an element at random\n",
    "    assert K<= len(obArr)\n",
    "    while K>=1:\n",
    "        num = obArr[np.random.randint(0,len(obArr))]\n",
    "        empArr.append([num])\n",
    "        obArr.remove(num)\n",
    "        K-=1\n",
    "    return obArr, empArr    \n",
    "        \n",
    "def pushSmallestDistOnce(arr_arr, elem_arr):\n",
    "    #find centre point if number of elements in seed_arr is > 1\n",
    "    for elem in elem_arr:\n",
    "        dist = []\n",
    "        for arr in arr_arr:\n",
    "    #        print(arr)\n",
    "            c_p = sum(arr)/len(arr)\n",
    "            dist.append(math.sqrt(abs(c_p - elem))) #distance between two points on the numberline\n",
    "        arr_arr[dist.index(min(dist))].append(elem)\n",
    "    return arr_arr\n",
    "\n",
    "\n",
    "def concat_small_to_big(arr_arr,cnt=5):\n",
    "    start = []\n",
    "    for i in arr_arr:\n",
    "        start += i\n",
    "    return start\n",
    "\n",
    "def redist(dist_arr,cnts):\n",
    "    arrx = concat_small_to_big(dist_arr)\n",
    "    while cnts>=1:\n",
    "        for elem in arrx:\n",
    "            dist = []\n",
    "            delted = False\n",
    "            for arr in dist_arr:\n",
    "                c_p = sum(arr)/len(arr)\n",
    "                dist.append(math.sqrt(abs(c_p - elem))) #distance between two points on the numberline\n",
    "                if elem in arr and not delted:\n",
    "#                     print('delted:yes')\n",
    "                    arr.remove(elem)\n",
    "                    delted=True\n",
    "            delted=False\n",
    "            dist_arr[dist.index(min(dist))].append(elem)\n",
    "        cnts -= 1\n",
    "    return dist_arr\n",
    "            \n",
    "    \n",
    "# cnt = 0\n",
    "# karr = []\n",
    "# while cnt<= k:\n",
    "#     karr.append()\n",
    "\n",
    "obs,seedArr = getKSeedArr(3,[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16])\n",
    "print(obs,seedArr)\n",
    "pushSmallestDistOnce(seedArr,obs)\n",
    "#rint(concat_small_to_big(seedArr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "0             5.1          3.5           1.4          0.2\n",
       "1             4.9          3.0           1.4          0.2\n",
       "2             4.7          3.2           1.3          0.2\n",
       "3             4.6          3.1           1.5          0.2\n",
       "4             5.0          3.6           1.4          0.2\n",
       "..            ...          ...           ...          ...\n",
       "145           6.7          3.0           5.2          2.3\n",
       "146           6.3          2.5           5.0          1.9\n",
       "147           6.5          3.0           5.2          2.0\n",
       "148           6.2          3.4           5.4          2.3\n",
       "149           5.9          3.0           5.1          1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat = df.drop([\"species\"], axis =1)\n",
    "df_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_arr = np.asarray(df_feat)\n",
    "mean_arr = np.sum(feat_arr, axis=0)/feat_arr.shape[0]\n",
    "std_arr = np.std(feat_arr, axis=0)\n",
    "\n",
    "norm_data = (feat_arr - mean_arr)/std_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-9.00681170e-01,  1.03205722e+00, -1.34127240e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.14301691e+00, -1.24957601e-01, -1.34127240e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.38535265e+00,  3.37848329e-01, -1.39813811e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.50652052e+00,  1.06445364e-01, -1.28440670e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.02184904e+00,  1.26346019e+00, -1.34127240e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-5.37177559e-01,  1.95766909e+00, -1.17067529e+00,\n",
       "        -1.05003079e+00],\n",
       "       [-1.50652052e+00,  8.00654259e-01, -1.34127240e+00,\n",
       "        -1.18150376e+00],\n",
       "       [-1.02184904e+00,  8.00654259e-01, -1.28440670e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.74885626e+00, -3.56360566e-01, -1.34127240e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.14301691e+00,  1.06445364e-01, -1.28440670e+00,\n",
       "        -1.44444970e+00],\n",
       "       [-5.37177559e-01,  1.49486315e+00, -1.28440670e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.26418478e+00,  8.00654259e-01, -1.22754100e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.26418478e+00, -1.24957601e-01, -1.34127240e+00,\n",
       "        -1.44444970e+00],\n",
       "       [-1.87002413e+00, -1.24957601e-01, -1.51186952e+00,\n",
       "        -1.44444970e+00],\n",
       "       [-5.25060772e-02,  2.18907205e+00, -1.45500381e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.73673948e-01,  3.11468391e+00, -1.28440670e+00,\n",
       "        -1.05003079e+00],\n",
       "       [-5.37177559e-01,  1.95766909e+00, -1.39813811e+00,\n",
       "        -1.05003079e+00],\n",
       "       [-9.00681170e-01,  1.03205722e+00, -1.34127240e+00,\n",
       "        -1.18150376e+00],\n",
       "       [-1.73673948e-01,  1.72626612e+00, -1.17067529e+00,\n",
       "        -1.18150376e+00],\n",
       "       [-9.00681170e-01,  1.72626612e+00, -1.28440670e+00,\n",
       "        -1.18150376e+00],\n",
       "       [-5.37177559e-01,  8.00654259e-01, -1.17067529e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-9.00681170e-01,  1.49486315e+00, -1.28440670e+00,\n",
       "        -1.05003079e+00],\n",
       "       [-1.50652052e+00,  1.26346019e+00, -1.56873522e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-9.00681170e-01,  5.69251294e-01, -1.17067529e+00,\n",
       "        -9.18557817e-01],\n",
       "       [-1.26418478e+00,  8.00654259e-01, -1.05694388e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.02184904e+00, -1.24957601e-01, -1.22754100e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.02184904e+00,  8.00654259e-01, -1.22754100e+00,\n",
       "        -1.05003079e+00],\n",
       "       [-7.79513300e-01,  1.03205722e+00, -1.28440670e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-7.79513300e-01,  8.00654259e-01, -1.34127240e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.38535265e+00,  3.37848329e-01, -1.22754100e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.26418478e+00,  1.06445364e-01, -1.22754100e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-5.37177559e-01,  8.00654259e-01, -1.28440670e+00,\n",
       "        -1.05003079e+00],\n",
       "       [-7.79513300e-01,  2.42047502e+00, -1.28440670e+00,\n",
       "        -1.44444970e+00],\n",
       "       [-4.16009689e-01,  2.65187798e+00, -1.34127240e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.14301691e+00,  1.06445364e-01, -1.28440670e+00,\n",
       "        -1.44444970e+00],\n",
       "       [-1.02184904e+00,  3.37848329e-01, -1.45500381e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-4.16009689e-01,  1.03205722e+00, -1.39813811e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.14301691e+00,  1.06445364e-01, -1.28440670e+00,\n",
       "        -1.44444970e+00],\n",
       "       [-1.74885626e+00, -1.24957601e-01, -1.39813811e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-9.00681170e-01,  8.00654259e-01, -1.28440670e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.02184904e+00,  1.03205722e+00, -1.39813811e+00,\n",
       "        -1.18150376e+00],\n",
       "       [-1.62768839e+00, -1.74477836e+00, -1.39813811e+00,\n",
       "        -1.18150376e+00],\n",
       "       [-1.74885626e+00,  3.37848329e-01, -1.39813811e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.02184904e+00,  1.03205722e+00, -1.22754100e+00,\n",
       "        -7.87084847e-01],\n",
       "       [-9.00681170e-01,  1.72626612e+00, -1.05694388e+00,\n",
       "        -1.05003079e+00],\n",
       "       [-1.26418478e+00, -1.24957601e-01, -1.34127240e+00,\n",
       "        -1.18150376e+00],\n",
       "       [-9.00681170e-01,  1.72626612e+00, -1.22754100e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.50652052e+00,  3.37848329e-01, -1.34127240e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-6.58345429e-01,  1.49486315e+00, -1.28440670e+00,\n",
       "        -1.31297673e+00],\n",
       "       [-1.02184904e+00,  5.69251294e-01, -1.34127240e+00,\n",
       "        -1.31297673e+00],\n",
       "       [ 1.40150837e+00,  3.37848329e-01,  5.35295827e-01,\n",
       "         2.64698913e-01],\n",
       "       [ 6.74501145e-01,  3.37848329e-01,  4.21564419e-01,\n",
       "         3.96171883e-01],\n",
       "       [ 1.28034050e+00,  1.06445364e-01,  6.49027235e-01,\n",
       "         3.96171883e-01],\n",
       "       [-4.16009689e-01, -1.74477836e+00,  1.37235899e-01,\n",
       "         1.33225943e-01],\n",
       "       [ 7.95669016e-01, -5.87763531e-01,  4.78430123e-01,\n",
       "         3.96171883e-01],\n",
       "       [-1.73673948e-01, -5.87763531e-01,  4.21564419e-01,\n",
       "         1.33225943e-01],\n",
       "       [ 5.53333275e-01,  5.69251294e-01,  5.35295827e-01,\n",
       "         5.27644853e-01],\n",
       "       [-1.14301691e+00, -1.51337539e+00, -2.60824029e-01,\n",
       "        -2.61192967e-01],\n",
       "       [ 9.16836886e-01, -3.56360566e-01,  4.78430123e-01,\n",
       "         1.33225943e-01],\n",
       "       [-7.79513300e-01, -8.19166497e-01,  8.03701950e-02,\n",
       "         2.64698913e-01],\n",
       "       [-1.02184904e+00, -2.43898725e+00, -1.47092621e-01,\n",
       "        -2.61192967e-01],\n",
       "       [ 6.86617933e-02, -1.24957601e-01,  2.50967307e-01,\n",
       "         3.96171883e-01],\n",
       "       [ 1.89829664e-01, -1.97618132e+00,  1.37235899e-01,\n",
       "        -2.61192967e-01],\n",
       "       [ 3.10997534e-01, -3.56360566e-01,  5.35295827e-01,\n",
       "         2.64698913e-01],\n",
       "       [-2.94841818e-01, -3.56360566e-01, -9.02269170e-02,\n",
       "         1.33225943e-01],\n",
       "       [ 1.03800476e+00,  1.06445364e-01,  3.64698715e-01,\n",
       "         2.64698913e-01],\n",
       "       [-2.94841818e-01, -1.24957601e-01,  4.21564419e-01,\n",
       "         3.96171883e-01],\n",
       "       [-5.25060772e-02, -8.19166497e-01,  1.94101603e-01,\n",
       "        -2.61192967e-01],\n",
       "       [ 4.32165405e-01, -1.97618132e+00,  4.21564419e-01,\n",
       "         3.96171883e-01],\n",
       "       [-2.94841818e-01, -1.28197243e+00,  8.03701950e-02,\n",
       "        -1.29719997e-01],\n",
       "       [ 6.86617933e-02,  3.37848329e-01,  5.92161531e-01,\n",
       "         7.90590793e-01],\n",
       "       [ 3.10997534e-01, -5.87763531e-01,  1.37235899e-01,\n",
       "         1.33225943e-01],\n",
       "       [ 5.53333275e-01, -1.28197243e+00,  6.49027235e-01,\n",
       "         3.96171883e-01],\n",
       "       [ 3.10997534e-01, -5.87763531e-01,  5.35295827e-01,\n",
       "         1.75297293e-03],\n",
       "       [ 6.74501145e-01, -3.56360566e-01,  3.07833011e-01,\n",
       "         1.33225943e-01],\n",
       "       [ 9.16836886e-01, -1.24957601e-01,  3.64698715e-01,\n",
       "         2.64698913e-01],\n",
       "       [ 1.15917263e+00, -5.87763531e-01,  5.92161531e-01,\n",
       "         2.64698913e-01],\n",
       "       [ 1.03800476e+00, -1.24957601e-01,  7.05892939e-01,\n",
       "         6.59117823e-01],\n",
       "       [ 1.89829664e-01, -3.56360566e-01,  4.21564419e-01,\n",
       "         3.96171883e-01],\n",
       "       [-1.73673948e-01, -1.05056946e+00, -1.47092621e-01,\n",
       "        -2.61192967e-01],\n",
       "       [-4.16009689e-01, -1.51337539e+00,  2.35044910e-02,\n",
       "        -1.29719997e-01],\n",
       "       [-4.16009689e-01, -1.51337539e+00, -3.33612130e-02,\n",
       "        -2.61192967e-01],\n",
       "       [-5.25060772e-02, -8.19166497e-01,  8.03701950e-02,\n",
       "         1.75297293e-03],\n",
       "       [ 1.89829664e-01, -8.19166497e-01,  7.62758643e-01,\n",
       "         5.27644853e-01],\n",
       "       [-5.37177559e-01, -1.24957601e-01,  4.21564419e-01,\n",
       "         3.96171883e-01],\n",
       "       [ 1.89829664e-01,  8.00654259e-01,  4.21564419e-01,\n",
       "         5.27644853e-01],\n",
       "       [ 1.03800476e+00,  1.06445364e-01,  5.35295827e-01,\n",
       "         3.96171883e-01],\n",
       "       [ 5.53333275e-01, -1.74477836e+00,  3.64698715e-01,\n",
       "         1.33225943e-01],\n",
       "       [-2.94841818e-01, -1.24957601e-01,  1.94101603e-01,\n",
       "         1.33225943e-01],\n",
       "       [-4.16009689e-01, -1.28197243e+00,  1.37235899e-01,\n",
       "         1.33225943e-01],\n",
       "       [-4.16009689e-01, -1.05056946e+00,  3.64698715e-01,\n",
       "         1.75297293e-03],\n",
       "       [ 3.10997534e-01, -1.24957601e-01,  4.78430123e-01,\n",
       "         2.64698913e-01],\n",
       "       [-5.25060772e-02, -1.05056946e+00,  1.37235899e-01,\n",
       "         1.75297293e-03],\n",
       "       [-1.02184904e+00, -1.74477836e+00, -2.60824029e-01,\n",
       "        -2.61192967e-01],\n",
       "       [-2.94841818e-01, -8.19166497e-01,  2.50967307e-01,\n",
       "         1.33225943e-01],\n",
       "       [-1.73673948e-01, -1.24957601e-01,  2.50967307e-01,\n",
       "         1.75297293e-03],\n",
       "       [-1.73673948e-01, -3.56360566e-01,  2.50967307e-01,\n",
       "         1.33225943e-01],\n",
       "       [ 4.32165405e-01, -3.56360566e-01,  3.07833011e-01,\n",
       "         1.33225943e-01],\n",
       "       [-9.00681170e-01, -1.28197243e+00, -4.31421141e-01,\n",
       "        -1.29719997e-01],\n",
       "       [-1.73673948e-01, -5.87763531e-01,  1.94101603e-01,\n",
       "         1.33225943e-01],\n",
       "       [ 5.53333275e-01,  5.69251294e-01,  1.27454998e+00,\n",
       "         1.71090158e+00],\n",
       "       [-5.25060772e-02, -8.19166497e-01,  7.62758643e-01,\n",
       "         9.22063763e-01],\n",
       "       [ 1.52267624e+00, -1.24957601e-01,  1.21768427e+00,\n",
       "         1.18500970e+00],\n",
       "       [ 5.53333275e-01, -3.56360566e-01,  1.04708716e+00,\n",
       "         7.90590793e-01],\n",
       "       [ 7.95669016e-01, -1.24957601e-01,  1.16081857e+00,\n",
       "         1.31648267e+00],\n",
       "       [ 2.12851559e+00, -1.24957601e-01,  1.61574420e+00,\n",
       "         1.18500970e+00],\n",
       "       [-1.14301691e+00, -1.28197243e+00,  4.21564419e-01,\n",
       "         6.59117823e-01],\n",
       "       [ 1.76501198e+00, -3.56360566e-01,  1.44514709e+00,\n",
       "         7.90590793e-01],\n",
       "       [ 1.03800476e+00, -1.28197243e+00,  1.16081857e+00,\n",
       "         7.90590793e-01],\n",
       "       [ 1.64384411e+00,  1.26346019e+00,  1.33141568e+00,\n",
       "         1.71090158e+00],\n",
       "       [ 7.95669016e-01,  3.37848329e-01,  7.62758643e-01,\n",
       "         1.05353673e+00],\n",
       "       [ 6.74501145e-01, -8.19166497e-01,  8.76490051e-01,\n",
       "         9.22063763e-01],\n",
       "       [ 1.15917263e+00, -1.24957601e-01,  9.90221459e-01,\n",
       "         1.18500970e+00],\n",
       "       [-1.73673948e-01, -1.28197243e+00,  7.05892939e-01,\n",
       "         1.05353673e+00],\n",
       "       [-5.25060772e-02, -5.87763531e-01,  7.62758643e-01,\n",
       "         1.57942861e+00],\n",
       "       [ 6.74501145e-01,  3.37848329e-01,  8.76490051e-01,\n",
       "         1.44795564e+00],\n",
       "       [ 7.95669016e-01, -1.24957601e-01,  9.90221459e-01,\n",
       "         7.90590793e-01],\n",
       "       [ 2.24968346e+00,  1.72626612e+00,  1.67260991e+00,\n",
       "         1.31648267e+00],\n",
       "       [ 2.24968346e+00, -1.05056946e+00,  1.78634131e+00,\n",
       "         1.44795564e+00],\n",
       "       [ 1.89829664e-01, -1.97618132e+00,  7.05892939e-01,\n",
       "         3.96171883e-01],\n",
       "       [ 1.28034050e+00,  3.37848329e-01,  1.10395287e+00,\n",
       "         1.44795564e+00],\n",
       "       [-2.94841818e-01, -5.87763531e-01,  6.49027235e-01,\n",
       "         1.05353673e+00],\n",
       "       [ 2.24968346e+00, -5.87763531e-01,  1.67260991e+00,\n",
       "         1.05353673e+00],\n",
       "       [ 5.53333275e-01, -8.19166497e-01,  6.49027235e-01,\n",
       "         7.90590793e-01],\n",
       "       [ 1.03800476e+00,  5.69251294e-01,  1.10395287e+00,\n",
       "         1.18500970e+00],\n",
       "       [ 1.64384411e+00,  3.37848329e-01,  1.27454998e+00,\n",
       "         7.90590793e-01],\n",
       "       [ 4.32165405e-01, -5.87763531e-01,  5.92161531e-01,\n",
       "         7.90590793e-01],\n",
       "       [ 3.10997534e-01, -1.24957601e-01,  6.49027235e-01,\n",
       "         7.90590793e-01],\n",
       "       [ 6.74501145e-01, -5.87763531e-01,  1.04708716e+00,\n",
       "         1.18500970e+00],\n",
       "       [ 1.64384411e+00, -1.24957601e-01,  1.16081857e+00,\n",
       "         5.27644853e-01],\n",
       "       [ 1.88617985e+00, -5.87763531e-01,  1.33141568e+00,\n",
       "         9.22063763e-01],\n",
       "       [ 2.49201920e+00,  1.72626612e+00,  1.50201279e+00,\n",
       "         1.05353673e+00],\n",
       "       [ 6.74501145e-01, -5.87763531e-01,  1.04708716e+00,\n",
       "         1.31648267e+00],\n",
       "       [ 5.53333275e-01, -5.87763531e-01,  7.62758643e-01,\n",
       "         3.96171883e-01],\n",
       "       [ 3.10997534e-01, -1.05056946e+00,  1.04708716e+00,\n",
       "         2.64698913e-01],\n",
       "       [ 2.24968346e+00, -1.24957601e-01,  1.33141568e+00,\n",
       "         1.44795564e+00],\n",
       "       [ 5.53333275e-01,  8.00654259e-01,  1.04708716e+00,\n",
       "         1.57942861e+00],\n",
       "       [ 6.74501145e-01,  1.06445364e-01,  9.90221459e-01,\n",
       "         7.90590793e-01],\n",
       "       [ 1.89829664e-01, -1.24957601e-01,  5.92161531e-01,\n",
       "         7.90590793e-01],\n",
       "       [ 1.28034050e+00,  1.06445364e-01,  9.33355755e-01,\n",
       "         1.18500970e+00],\n",
       "       [ 1.03800476e+00,  1.06445364e-01,  1.04708716e+00,\n",
       "         1.57942861e+00],\n",
       "       [ 1.28034050e+00,  1.06445364e-01,  7.62758643e-01,\n",
       "         1.44795564e+00],\n",
       "       [-5.25060772e-02, -8.19166497e-01,  7.62758643e-01,\n",
       "         9.22063763e-01],\n",
       "       [ 1.15917263e+00,  3.37848329e-01,  1.21768427e+00,\n",
       "         1.44795564e+00],\n",
       "       [ 1.03800476e+00,  5.69251294e-01,  1.10395287e+00,\n",
       "         1.71090158e+00],\n",
       "       [ 1.03800476e+00, -1.24957601e-01,  8.19624347e-01,\n",
       "         1.44795564e+00],\n",
       "       [ 5.53333275e-01, -1.28197243e+00,  7.05892939e-01,\n",
       "         9.22063763e-01],\n",
       "       [ 7.95669016e-01, -1.24957601e-01,  8.19624347e-01,\n",
       "         1.05353673e+00],\n",
       "       [ 4.32165405e-01,  8.00654259e-01,  9.33355755e-01,\n",
       "         1.44795564e+00],\n",
       "       [ 6.86617933e-02, -1.24957601e-01,  7.62758643e-01,\n",
       "         7.90590793e-01]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std_scale = preprocessing.StandardScaler().fit(feat_arr)\n",
    "# df_std = std_scale.transform(feat_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 µs, sys: 0 ns, total: 9 µs\n",
      "Wall time: 16.2 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(norm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_df= df.replace({'species':{'setosa':1,'versicolor':2,'virginica':0}})\n",
    "\n",
    "old_df['predicted']=kmeans.labels_\n",
    "\n",
    "wrong = old_df[old_df['predicted']!=old_df['species']]\n",
    "# it seems that versicolor and virginica look similar\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "from sklearn.metrics.pairwise import pairwise_distances_argmin\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generating random data and labels\n",
    "np.random.seed(0)\n",
    "centers = [[1,1],[-1,-1],[1,-1]]\n",
    "n_clus = len(centers)\n",
    "X,labels_true = make_blobs(n_samples=5000, centers=centers, cluster_std=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=3, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SIMPLE KMEANS CLUSTERING\n",
    "k_means = KMeans(init='k-means++', n_clusters=n_clus, n_init=10)\n",
    "k_means.fit(X)\n",
    "\n",
    "#X['equal']= labels_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means.labels_\n",
    "df = pd.DataFrame(X)\n",
    "df['pred'] = k_means.labels_\n",
    "df['actual'] = labels_true\n",
    "df['pred'].unique()\n",
    "df['actual'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#how well does it work:\n",
    "\n",
    "pc1 = df[df['pred']==1].index\n",
    "pc2 = df[df['pred']==2].index\n",
    "pc3 = df[df['pred']==0].index\n",
    "\n",
    "ac1 = df[df['actual']==1].index\n",
    "ac2 = df[df['actual']==2].index\n",
    "ac3 = df[df['actual']==0].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144,) (228,) (132,)\n",
      "error classification 10.08\n"
     ]
    }
   ],
   "source": [
    "miss1 = np.setdiff1d(np.union1d(pc1,ac1),ac1)\n",
    "miss2 = np.setdiff1d(np.union1d(pc2,ac2),ac2)\n",
    "miss3 = np.setdiff1d(np.union1d(pc3,ac3),ac3)\n",
    "print(miss1.shape, miss2.shape, miss3.shape)\n",
    "improper_classificaton = miss1.shape[0]+miss2.shape[0]+miss3.shape[0]\n",
    "err = (100*improper_classificaton)/df.shape[0]\n",
    "print('error classification',err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means with mini-batching\n",
    "\n",
    "The algorithm iterates between two major steps:\n",
    "1. In the first step, samples are drawn randomly from the dataset, to form a mini-batch. These are then assigned to the nearest centroid. \n",
    "2. In the second step, the centroids are updated. In contrast to k-means, this is done on a per-sample basis. \n",
    "\n",
    "**For each sample in the mini-batch, the assigned centroid is updated by taking the streaming average of the sample and all previous samples assigned to that centroid. This has the effect of decreasing the rate of change for a centroid over time. These steps are performed until convergence or a predetermined number of iterations is reached.**\n",
    "\n",
    "`MiniBatchKMeans converges faster than KMeans, but the quality of the results is reduced.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 2) (5000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,labels_true.shape)\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MiniBatchKMeans(batch_size=200, compute_labels=True, init='k-means++',\n",
       "                init_size=None, max_iter=100, max_no_improvement=10,\n",
       "                n_clusters=3, n_init=3, random_state=None,\n",
       "                reassignment_ratio=0.01, tol=0.0, verbose=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MiniBatchKMeans(init=\"k-means++\",batch_size=batch_size,verbose=0,n_clusters=3)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157,) (124,) (227,)\n",
      "error classification 10.16\n"
     ]
    }
   ],
   "source": [
    "dfMini = pd.DataFrame(X)\n",
    "dfMini['pred'] = model.labels_\n",
    "dfMini['actual'] = labels_true\n",
    "\n",
    "#how well does it work:\n",
    "#The pred, actual values vary in each re-run\n",
    "#if the result seems wrong it is due to the fact that the data has been classifed in uneven clusters\n",
    "pc1 = dfMini[dfMini['pred']==1].index\n",
    "pc2 = dfMini[dfMini['pred']==2].index\n",
    "pc3 = dfMini[dfMini['pred']==0].index\n",
    "\n",
    "ac1 = dfMini[dfMini['actual']==1].index\n",
    "ac2 = dfMini[dfMini['actual']==0].index\n",
    "ac3 = dfMini[dfMini['actual']==2].index\n",
    "\n",
    "miss1 = np.setdiff1d(np.union1d(pc1,ac1),ac1)\n",
    "miss2 = np.setdiff1d(np.union1d(pc2,ac2),ac2)\n",
    "miss3 = np.setdiff1d(np.union1d(pc3,ac3),ac3)\n",
    "print(miss1.shape, miss2.shape, miss3.shape)\n",
    "improper_classificaton = miss1.shape[0]+miss2.shape[0]+miss3.shape[0]\n",
    "err = (100*improper_classificaton)/df.shape[0]\n",
    "print('error classification',err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Distribution\n",
    "$p(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{(x-\\mu)^{2}}{2 \\sigma^{2}}}$\n",
    "\n",
    "$\\sigma$ - standard deviation \n",
    "\n",
    "$\\sigma^{2} = VAR$  \n",
    "&nbsp; &nbsp; **OR**     \n",
    "$\\sigma = \\sqrt{var}$\n",
    "\n",
    "It creates a bell shaped curve of the distribution and the area under the curve tells us the probabilty of those values occuring.\n",
    "It always has to be a range.\n",
    "So the probability of x:\n",
    "$$   x\\in \\left( 3,5 \\right) = \\int_{a}^{b} \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{(x-\\mu)^{2}}{2 \\sigma^{2}}} dx$$  \n",
    "\n",
    "Similarly the CDF (commulative density function) is probability upto x:\n",
    "$$ cdf(x) = \\int_{-\\infty}^{x} \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{(x-\\mu)^{2}}{2 \\sigma^{2}}}$$\n",
    "\n",
    "Assuming the normal distribution:\n",
    "probabilty percent for\n",
    "\n",
    "| no of sds|probabilty percent|\n",
    "|----------|------------------|\n",
    "|1|62.27|\n",
    "|2||\n",
    "|3|99.73|\n",
    "\n",
    "## Gaussian Distribution (Multivariate)\n",
    "\n",
    "$$ \\mathcal{N}\\left( x; \\mu,\\sum\\right) = \\frac{1}{\\left(2\\pi \\right)^{\\frac{d}{2}}}\\bigg| \\sum \\bigg|^\\frac{-1}{ 2 } exp\\bigg\\{- \\frac{1}{2}\\left(\\underrightarrow{x} -\\underrightarrow{\\mu}  \\right) \\sum^{-1}\\left(\\underrightarrow{x} -\\underrightarrow{\\mu}  \\right)^{T}\\bigg\\}$$\n",
    "\n",
    "For the above equation let:\n",
    "\n",
    "$\\mu = $ **length-d row vector**\n",
    "\n",
    "$\\sum =$ **dxd matrix**\n",
    "\n",
    "$\\big|\\sum\\big| =$ **matrix determinant**\n",
    "\n",
    "#### Central Limit Theorem\n",
    "\n",
    "\n",
    "## Mixture Models\n",
    "* soft clustering\n",
    "* Probabilistically-grounded way of doing clustering.\n",
    "\n",
    "### EM- Expectation Maximization Algorithm\n",
    "- automatically discover all parameters for K sources\n",
    "\n",
    "### Mixture Models in 1-D\n",
    "**Observations are `one dimentional` i.e. $ x_{1}...x_{n}$**\n",
    "\n",
    " If we have the following situation:\n",
    "1. We know the source of the values is 2. Therefore we can expect the two values to have two distinct dist. In this case $\\mu, \\sigma^{2}$ are unknown. But we know the sources so we assume two distribution and find two separate $\\mu, \\sigma^{2}$.\n",
    "\n",
    "2. If we do not know the sources of the points but we are aware of different $\\mu, \\sigma^{2}$ we can guess the probabilities of a point lying in either of the region a or region b.\n",
    "$$P\\left(x_{i}|b\\right) = \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}} exp\\bigg(\\frac{-\\left(x_{i}-\\mu_{b}\\right)^{2}}{2\\sigma^{2}_{b}}\\bigg)$$\n",
    "The above gives the probability of $x_{i}$ which we can use to calculate $P\\left(b|x_{i}\\right)$ using the bayes rule as following:\n",
    "\n",
    "$$P\\left(b|x_{i}\\right) = \\frac{P\\left(x_{i}|b\\right) P\\left(b\\right)}{P\\left(x_{i}|b\\right) P\\left(b\\right)+P\\left(x_{i}|a\\right) P\\left(a\\right)}$$\n",
    "\n",
    "Similarly we can calculate the $P\\left(x_{i}|a\\right)$\n",
    "See which is greater to find where $x_{i}$ lies\n",
    "\n",
    "3. In case both 1 and 2 are unknown, we use the **EM** algorithm is used. It takes the following steps:\n",
    "\n",
    ">a. Starts with two random gaussians $\\left(\\mu_{a},\\sigma_{a}^{2}\\right), \\left(\\mu_{b},\\sigma_{b}^{2}\\right)$.\\\n",
    "where:\\\n",
    "$$\\mu_{b} = \\frac{b_{1}x_{1}+b_{2}x_{2}...b_{i}x_{i}}{b_{1}+b_{2}...b_{i}} $$ \n",
    "$$ \\sigma^{2} = \\frac{b_{1}\\left(x_{1}-\\mu_{1}\\right)^{2}+b_{2}\\left(x_{2}-\\mu_{2}\\right)^{2}...b_{i}\\left(x_{i}-\\mu_{i}\\right)^{2}}{b_{1}+b_{2}...b_{i}}$$\n",
    "\n",
    ">b. Calculates for each point the probabilities $ b_{i}=P\\left(b|x_{i}\\right), a_{i}=P\\left(a|x_{i}\\right)$ Where $a_{i}=1-b{i}$\n",
    "\n",
    "\n",
    ">c. Adjusts and re-estimate  $\\left(\\mu_{a},\\sigma_{a}^{2}\\right), \\left(\\mu_{b},\\sigma_{b}^{2}\\right)$.\n",
    "\n",
    "\n",
    "**Bayes Theorem**\n",
    "\n",
    "Useful notations:\n",
    "$P\\left(A|B\\right)$ means probability of A given B and it is equal to $P\\left(A|B\\right) = \\frac{\\left(A\\cap B\\right)}{P\\left(B\\right)}$\n",
    "\n",
    "If we are aware of the probability of B given A, then we can calculate the probability of A given B using the **Bayes Theorem**:\n",
    "$$P\\left(A|B\\right) = \\frac{P\\left(B|A\\right).P\\left(A\\right)}{P\\left(B\\right)}$$\n",
    "\n",
    "\n",
    "#### MODEL EVALUATION TECHNIQUES\n",
    "\n",
    "|SNo.|Model Parameters|Model Hyperparameters|\n",
    "|-----|----------------|---------------------|\n",
    "|1|A model parameter is a configuration variable that is internal to the model and whose value can be estimated from data|A model hyperparameter is a configuration that is external to the model and whose value cannot be estimated from data.|\n",
    "|2|They are required by the model when making predictions|They are often used in processes to help estimate model parameters.|\n",
    "|3|They values define the skill of the model on your problem.||\n",
    "|4|They are estimated or learned from data.|They can often be set using heuristics.|\n",
    "|5|They are often not set manually by the practitioner.|They are often specified by the practitioner.|\n",
    "|6|They are often saved as part of the learned model.||\n",
    "|7|Often model parameters are estimated using an optimization algorithm, which is a type of efficient search through possible parameter values.|They are often tuned for a given predictive modeling problem.|\n",
    "|8|e.g. Weights of neural networks, coefficient of linear regression|e.g. The learning rate of neural networks,`k` in k-means clustering|\n",
    "\n",
    "\n",
    "\n",
    "Things required to fully understand it:\n",
    "`Maximum Likelihood Estimation`\n",
    "To understand `maximum likelihood estimation`\n",
    "`Probability Distribution, Random Variables, Joint Probability Distribution`\n",
    "\n",
    "\n",
    "#### Probability Vs Likelihood\n",
    "\n",
    "Let there be a normal distribution curve described by:\n",
    "\n",
    "$\\mu=32,\\sigma=2.5$\n",
    "\n",
    "1. Probability for x<24 is discribed as:\\\n",
    "$P\\left(x>24|\\mu=32,\\sigma=2.5\\right) $\\\n",
    "Thus we can change left side of `|` to change the probability.\\\n",
    "And it is described by:\\\n",
    "Area under the curve $P\\left(x|\\mu,\\sigma\\right)\\bigg|_\\left(x<24\\right)$\n",
    "2. Likelihood is calculated after the measure of `x` sample is fixed.For e.g. when x=24 is described as:\\\n",
    "$$L\\left(\\mu=a,\\sigma=b|x=24\\right)$$\n",
    "It is a point on the curve i.e the `y` axis value for the fixed x, where y=f(x) unlike probability that is the area of the distribution. We adjust the $\\mu, \\sigma$ to change the likelihood of the fixed `x` value.\n",
    "\n",
    "\n",
    "|Sno|Probability|Likelihood|\n",
    "|---|-----------|----------|\n",
    "|1  |Are area under a fixed distribution|y-axis values for fixed data points with variable distributions| \n",
    "|2|The curve is fixed|The value of `x` is fixed|\n",
    "\n",
    "#### Maximum Likelihood\n",
    "The goal of maximum likelihood is to find the optimal way to fit a distribution to the data.\n",
    "\n",
    "\n",
    "##### Probabilistic Model Selection\n",
    "Provides an analytical technique for scoring and choosing among candidate models.\n",
    "Models are evaluated both on \n",
    "1. The performance on the training data set.\\\n",
    "e.g. estimated with maximum likelihood estimation\n",
    "2. Complexity Of the model.\\\n",
    "e.g. by no. of the degrees of freedom or number of params\n",
    "\n",
    "###### Advantages:\n",
    "1. Test data is not required, meaning all the data can be used to fit the model.\n",
    "\n",
    "###### Disadvantages:\n",
    "1. Same general statistic cannot be calculated across a range of different types of models. Instead, the metric must be carefully derived for each model.\n",
    "2. They do not take the uncertainty of the model into account but they tend to favour overly simple models.\n",
    "\n",
    "\n",
    "1. Akaike Information Criterion \n",
    "2. Bayesian Information Criterion \n",
    "3. Minimum Description Length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7f61ff749710>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate normal distribution values\n",
    "#improve the graph by using the xaxis [0...n], y=1/sqrt(2 pi \\sigma^{2} )\n",
    "# https://www.youtube.com/watch?v=Dn6b9fCIUpM&t=41s\n",
    "import math\n",
    "\n",
    "def normal_vals(mu, sigma,x):\n",
    "    pow_e = -math.pow(x-mu,2)/(2*math.pow(sigma,2))\n",
    "    return math.exp(pow_e)/math.sqrt(2*math.pi*math.pow(sigma,2))\n",
    "    \n",
    "\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "\n",
    "xaxis = list(range(1,40))\n",
    "yaxis = list(map(lambda x: normal_vals(32,4,x), xaxis))\n",
    "\n",
    "\n",
    "assert len(xaxis)== len(yaxis)\n",
    "\n",
    "fig = pyplot.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(xaxis,yaxis)\n",
    "ax.axvline(x=32,linewidth=1, color='r')\n",
    "\n",
    "# To obtain the maximum likelihood we ju\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the maximum likelihood $\\sigma, \\mu$\n",
    "\n",
    "1. Fix the $\\sigma$ value and change the $\\mu$ value to find the maximum, which is where the slope given by the function\n",
    "$$f\\left(x_{i}|b\\right) = \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}} exp\\bigg(\\frac{-\\left(x-\\mu\\right)^{2}}{2\\sigma^{2}}\\bigg)$$\n",
    "Its value where the slope of the curve is `0` is the maximum likelihood $\\mu$ of the function.\n",
    "2. Fix the $\\mu$ and calculate the value of $\\sigma$ next.\n",
    "3. The above was the likelihood determination given `1` x. For finding the maximum likelihood given two `independant` x valuese e.g.\n",
    "\n",
    "$L\\left(\\mu=28, \\sigma=2|x1=32 and x2=34\\right)$\n",
    "We calculate L, separately with the above exponential function, e.g\n",
    "L at x1 = 32,34, and multiply their outcomes since their probabilities are independant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x (1000, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 500x170 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# %matplotlib inline\n",
    "#----------------------------------------------------------------------\n",
    "# This function adjusts matplotlib settings for a uniform feel in the textbook.\n",
    "# Note that with usetex=True, fonts are rendered with LaTeX.  This may\n",
    "# result in an error if LaTeX is not installed on your system.  In that case,\n",
    "# you can set usetex to False.\n",
    "if \"setup_text_plots\" not in globals():\n",
    "    from astroML.plotting import setup_text_plots\n",
    "setup_text_plots(fontsize=8, usetex=False)\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Set up the dataset.\n",
    "#  We'll create our dataset by drawing samples from Gaussians.\n",
    "\n",
    "random_state = np.random.RandomState(seed=1)\n",
    "\n",
    "X = np.concatenate([random_state.normal(-1, 1.5, 350),\n",
    "                    random_state.normal(0, 1, 500),\n",
    "                    random_state.normal(3, 0.5, 150)]).reshape(-1, 1)\n",
    "print('x',X.shape)\n",
    "#------------------------------------------------------------\n",
    "# Learn the best-fit GaussianMixture models\n",
    "#  Here we'll use scikit-learn's GaussianMixture model. The fit() method\n",
    "#  uses an Expectation-Maximization approach to find the best\n",
    "#  mixture of Gaussians for the data\n",
    "\n",
    "# fit models with 1-10 components\n",
    "N = np.arange(1, 11)\n",
    "models = [None for i in range(len(N))]\n",
    "\n",
    "for i in range(len(N)):\n",
    "    models[i] = GaussianMixture(N[i]).fit(X)\n",
    "    \n",
    "GaussianMixture?\n",
    "\n",
    "# compute the AIC and the BIC\n",
    "AIC = [m.aic(X) for m in models]\n",
    "BIC = [m.bic(X) for m in models]\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# Plot the results\n",
    "#  We'll use three panels:\n",
    "#   1) data + best-fit mixture\n",
    "#   2) AIC and BIC vs number of components\n",
    "#   3) probability that a point came from each component\n",
    "\n",
    "fig = plt.figure(figsize=(5, 1.7))\n",
    "fig.subplots_adjust(left=0.12, right=0.97,\n",
    "                    bottom=0.21, top=0.9, wspace=0.5)\n",
    "\n",
    "\n",
    "# plot 1: data + best-fit mixture\n",
    "ax = fig.add_subplot(131)\n",
    "M_best = models[np.argmin(AIC)]\n",
    "\n",
    "x = np.linspace(-6, 6, 1000)\n",
    "logprob = M_best.score_samples(x.reshape(-1, 1))\n",
    "responsibilities = M_best.predict_proba(x.reshape(-1, 1))\n",
    "pdf = np.exp(logprob)\n",
    "pdf_individual = responsibilities * pdf[:, np.newaxis]\n",
    "\n",
    "ax.hist(X, 30, density=True, histtype='stepfilled', alpha=0.4)\n",
    "ax.plot(x, pdf, '-k')\n",
    "ax.plot(x, pdf_individual, '--k')\n",
    "ax.text(0.04, 0.96, \"Best-fit Mixture\",\n",
    "        ha='left', va='top', transform=ax.transAxes)\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$p(x)$')\n",
    "\n",
    "\n",
    "# plot 2: AIC and BIC\n",
    "ax = fig.add_subplot(132)\n",
    "ax.plot(N, AIC, '-k', label='AIC')\n",
    "ax.plot(N, BIC, '--k', label='BIC')\n",
    "ax.set_xlabel('n. components')\n",
    "ax.set_ylabel('information criterion')\n",
    "ax.legend(loc=2)\n",
    "\n",
    "\n",
    "# plot 3: posterior probabilities for each component\n",
    "ax = fig.add_subplot(133)\n",
    "\n",
    "p = responsibilities\n",
    "p = p[:, (1, 0, 2)]  # rearrange order so the plot looks better\n",
    "p = p.cumsum(1).T\n",
    "\n",
    "ax.fill_between(x, 0, p[0], color='gray', alpha=0.3)\n",
    "ax.fill_between(x, p[0], p[1], color='gray', alpha=0.5)\n",
    "ax.fill_between(x, p[1], 1, color='gray', alpha=0.7)\n",
    "ax.set_xlim(-6, 6)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel(r'$p({\\rm class}|x)$')\n",
    "\n",
    "ax.text(-5, 0.3, 'class 1', rotation='vertical')\n",
    "ax.text(0, 0.5, 'class 2', rotation='vertical')\n",
    "ax.text(3, 0.3, 'class 3', rotation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Equation for Multivariate Gaussian Model\n",
    "Gaussian Density function for multivariate data:\n",
    "$$\\mathscr{N}\\left(\\underrightarrow{x};\\underrightarrow{\\mu},\\sum \\right) = \\frac{1}{\\left(2\\pi\\right)^{d/2}}\\bigg|\\sum^{-1/2}exp\\bigg\\{ -\\frac{1\\left(\\underrightarrow{x}-\\underrightarrow{\\mu}\\right)\\sum^{-1}\\left(\\underrightarrow{x}-\\underrightarrow{\\mu}\\right)^{T}}{2}\\bigg\\}$$\n",
    "\n",
    "This is the distribution that we are assuming,\n",
    "\n",
    "here: \n",
    "$\\mu$ - Length-d row vector\n",
    "\n",
    "$\\sum =$ dxd matrix\n",
    "\n",
    "$|\\mu|$ matrix determinant\n",
    "\n",
    "where:\n",
    "\n",
    "$\\hat{\\mu} = \\frac{1}{m}\\sum_{j}\\underrightarrow{x}^{j}$\n",
    "\n",
    "$\\hat{\\sum} = \\frac{1}{m}\\sum_{j}\\left(\\underrightarrow{x}^{j} - \\underrightarrow{\\hat{\\mu}}\\right)^{T}\\left(\\underrightarrow{x}^{j} - \\underrightarrow{\\hat{\\mu}}\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "features_df = df[df.columns.values[:-1]]\n",
    "labels_df = df[df.columns.values[-1]]\n",
    "\n",
    "def encode(series_arg:pd.Series):\n",
    "    rep_dict = {}\n",
    "    for i,dat in enumerate(series_arg.unique()):\n",
    "        rep_dict[dat]=i\n",
    "        series_arg = series_arg.replace(dat,i)\n",
    "    return series_arg,rep_dict\n",
    "  \n",
    "    \n",
    "train_feat,test_feat,train_lab,test_lab = train_test_split(features_df,labels_df,test_size=0.33)\n",
    "\n",
    "test_lab,test_enc = encode(test_lab)\n",
    "train_lab,train_enc = encode(train_lab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GMM(n_components=3).fit(train_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lab = gmm.predict(test_feat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with the missing values \n",
    "1. Drop the entire column with the missing values.\n",
    "2. Imputation - Fill the column. E.g. take the average of all the values in the column present and fill the missing values with those.\n",
    "3. Extension of imputation - Add the missing values as another feature. I.E maybe a colum as binay of missing values.\n",
    "\n",
    "eg:\n",
    ">|X   |Y|\n",
    "|----|-|\n",
    "|  1 |1|\n",
    "|  2 |1|\n",
    "|  3 |2|\n",
    "|NULL|2|\n",
    "\n",
    ">__CHANGES TO__\n",
    "\n",
    ">|X   |Y|Missing_X|\n",
    "|----|-|---------|\n",
    "|  1 |1|FALSE    |\n",
    "|  2 |1|FALSE    |\n",
    "|  3 |2|FALSE    |\n",
    "|NULL|2|TRUE     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with Categorical Variables:\n",
    "1. Dropping the categorical variables from the data. This approach will work well only when the columns dropped did not contain useful information.\n",
    "2. Label Encoding: Assigning unique value to a different integer.\n",
    "\n",
    "    e.g\n",
    "\n",
    ">|Col1|Col1(after label encoding)|\n",
    "|----|---------------------------|\n",
    "|categ1|       1                 |\n",
    "|categ2|       2                 |\n",
    "|categ3|       3                 |\n",
    "|categ1|       1                 |\n",
    "|categ3|       3                 |\n",
    "\n",
    "`Ordinal values` have a clear sence of sequencing in their order\n",
    "3. One hot encoding: It is the preference for the low cardinality of the features in the dataset as it results in the expansion of the size of the dataset.\n",
    "e.g.\n",
    "\n",
    "|col   |         \n",
    "|------|         \n",
    "|red   |         \n",
    "|red   |         \n",
    "|yellow|         \n",
    "|green |         \n",
    "|yellow|         \n",
    "\n",
    "| red|yellow|green|\n",
    "|----|------|-----|\n",
    "|1|0|0|\n",
    "|1|0|0|\n",
    "|0|1|0|\n",
    "|0|0|1|\n",
    "|0|1|0|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation\n",
    "<img src=\"./cross_valid.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "Cross-validation gives a more accurate measure of model quality, which is especially important if you are making a lot of modeling decisions. However, it can take longer to run, because it estimates multiple models (one for each fold).\n",
    "\n",
    "1. For small datasets, where extra computational burden isn't a big deal, you should run cross-validation.\n",
    "2. For larger datasets, a single validation set is sufficient. Your code will run faster, and you may have enough data that there's little need to re-use some of it for holdout.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting (Ensemble Method)\n",
    "Ensemble methods combine the predictions of several models (e.g., several trees, in the case of random forests).\n",
    "\n",
    "\n",
    "Gradient boosting is a method that goes through cycles to iteratively add models into an ensemble.\n",
    "It begins by initializing the ensemble with a single model, whose predictions can be pretty naive. (Even if its predictions are wildly inaccurate, subsequent additions to the ensemble will address those errors.)\n",
    "\n",
    "Then, we start the cycle:\n",
    "\n",
    "1. First, we use the current ensemble to generate predictions for each observation in the dataset. To make a prediction, we add the predictions from all models in the ensemble.\n",
    "2. These predictions are used to calculate a loss function (like mean squared error, for instance).\n",
    "3. Then, we use the loss function to fit a new model that will be added to the ensemble. Specifically, we determine model parameters so that adding this new model to the ensemble will reduce the loss. (Side note: The \"gradient\" in \"gradient boosting\" refers to the fact that we'll use gradient descent on the loss function to determine the parameters in this new model.)\n",
    "4. Finally, we add the new model to ensemble, and ...\n",
    "5. ... repeat!\n",
    "\n",
    "\n",
    "## Data Leakage\n",
    "Data leakage (or leakage) happens when your training data contains information about the target, but similar data will not be available when the model is used for prediction. \n",
    "\n",
    "The data leakage can be due to two prominent reasons:\n",
    "\n",
    "**1. Target leakage** :Target leakage occurs when your predictors include data that will not be available at the time you make predictions. \n",
    "\n",
    "**2. train-test contamination** :A different type of leak occurs when you aren't careful to distinguish training data from validation data.\n",
    "\n",
    "To avoid these types of problems never apply imputer or other type type of data processing before applying any algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_env_kernel",
   "language": "python",
   "name": "image_env_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
